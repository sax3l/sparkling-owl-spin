#!/usr/bin/env python3
"""
üîç TOTAL PROJECT CONTROL AND VALIDATION SYSTEM üîç

Denna fil genomf√∂r en omfattande kontroll av hela Sparkling Owl Spin projektet
f√∂r att s√§kerst√§lla att alla komponenter fungerar perfekt tillsammans.

KONTROLLOMR√ÖDEN:
‚úÖ Filstruktur och organisation
‚úÖ Kodkvalitet och syntax
‚úÖ Importberoenden och kompatibilitet
‚úÖ Konfiguration och inst√§llningar
‚úÖ Testning och validering
‚úÖ Dokumentation och struktur
‚úÖ Performance och optimering
‚úÖ Security och s√§kerhet
‚úÖ Enterprise-f√§rdighet
‚úÖ Skalbarhet och robusthet
"""

import asyncio
import ast
import json
import os
import sys
import time
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import importlib.util

class TotalProjectController:
    """Omfattande projektkontroll och validering"""
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.src_path = self.project_root / "src"
        self.sos_path = self.src_path / "sos"
        
        self.validation_results = {}
        self.issues_found = []
        self.recommendations = []
        self.performance_metrics = {}
        
        print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                                          ‚ïë
‚ïë                üîç TOTAL PROJECT CONTROL - SPARKLING OWL SPIN üîç                        ‚ïë
‚ïë                                                                                          ‚ïë
‚ïë                      üéØ COMPREHENSIVE VALIDATION AND OPTIMIZATION üéØ                   ‚ïë
‚ïë                                                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """)
    
    def validate_file_structure(self) -> Dict[str, Any]:
        """Kontrollera filstruktur och organisation"""
        print("\nüìÅ KONTROLLERAR FILSTRUKTUR OCH ORGANISATION:")
        print("=" * 80)
        
        structure_validation = {
            "status": "checking",
            "required_directories": [],
            "required_files": [],
            "optional_components": [],
            "structure_score": 0
        }
        
        # Kontrollera k√§rnkataloger
        required_dirs = [
            "src/sos",
            "src/sos/core", 
            "src/sos/crawler",
            "src/sos/proxy",
            "src/sos/stealth",
            "src/sos/captcha",
            "src/sos/exporters",
            "src/sos/scheduler",
            "tests",
            "docs"
        ]
        
        for dir_path in required_dirs:
            full_path = self.project_root / dir_path
            exists = full_path.exists()
            structure_validation["required_directories"].append({
                "path": dir_path,
                "exists": exists,
                "status": "‚úÖ OK" if exists else "‚ùå MISSING"
            })
            if exists:
                structure_validation["structure_score"] += 1
                print(f"   ‚úÖ {dir_path} - OK")
            else:
                print(f"   ‚ùå {dir_path} - MISSING")
                self.issues_found.append(f"Missing directory: {dir_path}")
        
        # Kontrollera k√§rnfiler
        required_files = [
            "src/sos/__init__.py",
            "src/sos/core/__init__.py",
            "src/sos/core/platform.py",
            "src/sos/proxy/advanced_pool.py",
            "src/sos/stealth/revolutionary_system.py", 
            "src/sos/captcha/revolutionary_solver.py",
            "requirements.txt",
            "setup.py",
            "README.md"
        ]
        
        for file_path in required_files:
            full_path = self.project_root / file_path
            exists = full_path.exists()
            size = full_path.stat().st_size if exists else 0
            structure_validation["required_files"].append({
                "path": file_path,
                "exists": exists,
                "size": size,
                "status": "‚úÖ OK" if exists and size > 0 else "‚ùå MISSING/EMPTY"
            })
            if exists and size > 0:
                structure_validation["structure_score"] += 1
                print(f"   ‚úÖ {file_path} - OK ({size} bytes)")
            else:
                print(f"   ‚ùå {file_path} - MISSING/EMPTY")
                self.issues_found.append(f"Missing/empty file: {file_path}")
        
        structure_validation["status"] = "completed"
        structure_validation["total_items"] = len(required_dirs) + len(required_files)
        structure_validation["success_rate"] = (structure_validation["structure_score"] / structure_validation["total_items"]) * 100
        
        self.validation_results["file_structure"] = structure_validation
        
        print(f"\nüìä Struktur Score: {structure_validation['structure_score']}/{structure_validation['total_items']} ({structure_validation['success_rate']:.1f}%)")
        
        return structure_validation
    
    def validate_code_syntax(self) -> Dict[str, Any]:
        """Kontrollera kodkvalitet och syntax"""
        print("\nüêç KONTROLLERAR KODKVALITET OCH SYNTAX:")
        print("=" * 80)
        
        syntax_validation = {
            "status": "checking",
            "files_checked": 0,
            "syntax_errors": [],
            "warnings": [],
            "quality_score": 0
        }
        
        # Hitta alla Python-filer
        python_files = list(self.project_root.rglob("*.py"))
        syntax_validation["total_files"] = len(python_files)
        
        for py_file in python_files:
            try:
                # Kontrollera syntax genom att kompilera
                with open(py_file, 'r', encoding='utf-8') as f:
                    source = f.read()
                
                # Kontrollera Python syntax
                ast.parse(source)
                syntax_validation["files_checked"] += 1
                syntax_validation["quality_score"] += 1
                print(f"   ‚úÖ {py_file.relative_to(self.project_root)} - Syntax OK")
                
                # Enkel kodkvalitetskontroll
                if len(source.splitlines()) > 1000:
                    syntax_validation["warnings"].append(f"Large file: {py_file.relative_to(self.project_root)} ({len(source.splitlines())} lines)")
                
            except SyntaxError as e:
                error_info = f"{py_file.relative_to(self.project_root)}:{e.lineno} - {e.msg}"
                syntax_validation["syntax_errors"].append(error_info)
                print(f"   ‚ùå {py_file.relative_to(self.project_root)} - Syntax Error: {e.msg}")
                self.issues_found.append(f"Syntax error in {error_info}")
                
            except UnicodeDecodeError as e:
                error_info = f"{py_file.relative_to(self.project_root)} - Encoding error"
                syntax_validation["syntax_errors"].append(error_info)
                print(f"   ‚ùå {py_file.relative_to(self.project_root)} - Encoding Error")
                self.issues_found.append(f"Encoding error in {error_info}")
            
            except Exception as e:
                error_info = f"{py_file.relative_to(self.project_root)} - {str(e)}"
                syntax_validation["warnings"].append(error_info)
                print(f"   ‚ö†Ô∏è {py_file.relative_to(self.project_root)} - Warning: {str(e)}")
        
        syntax_validation["status"] = "completed"
        syntax_validation["success_rate"] = (syntax_validation["quality_score"] / syntax_validation["total_files"]) * 100 if syntax_validation["total_files"] > 0 else 100
        
        self.validation_results["code_syntax"] = syntax_validation
        
        print(f"\nüìä Syntax Score: {syntax_validation['quality_score']}/{syntax_validation['total_files']} ({syntax_validation['success_rate']:.1f}%)")
        print(f"üìã Syntax Errors: {len(syntax_validation['syntax_errors'])}")
        print(f"‚ö†Ô∏è Warnings: {len(syntax_validation['warnings'])}")
        
        return syntax_validation
    
    def validate_import_dependencies(self) -> Dict[str, Any]:
        """Kontrollera importberoenden och kompatibilitet"""
        print("\nüì¶ KONTROLLERAR IMPORTBEROENDEN OCH KOMPATIBILITET:")
        print("=" * 80)
        
        import_validation = {
            "status": "checking",
            "core_imports": {},
            "revolutionary_imports": {},
            "missing_dependencies": [],
            "compatibility_score": 0
        }
        
        # Testa k√§rnimporter
        core_imports = [
            ("asyncio", "Standard Library"),
            ("pathlib", "Standard Library"), 
            ("json", "Standard Library"),
            ("datetime", "Standard Library"),
            ("logging", "Standard Library"),
            ("typing", "Standard Library"),
            ("dataclasses", "Standard Library"),
            ("abc", "Standard Library")
        ]
        
        print("   üîç Kontrollerar k√§rnimporter:")
        for module_name, source in core_imports:
            try:
                importlib.import_module(module_name)
                import_validation["core_imports"][module_name] = {"status": "‚úÖ OK", "source": source}
                import_validation["compatibility_score"] += 1
                print(f"     ‚úÖ {module_name} ({source}) - OK")
            except ImportError:
                import_validation["core_imports"][module_name] = {"status": "‚ùå MISSING", "source": source}
                import_validation["missing_dependencies"].append(f"Core: {module_name}")
                print(f"     ‚ùå {module_name} ({source}) - MISSING")
                self.issues_found.append(f"Missing core dependency: {module_name}")
        
        # Testa revolution√§ra komponenter (optional)
        revolutionary_imports = [
            ("aiohttp", "HTTP Client for Advanced Crawling"),
            ("selenium", "Browser Automation"),
            ("playwright", "Modern Browser Automation"),
            ("requests", "HTTP Library"),
            ("beautifulsoup4", "HTML Parsing"),
            ("lxml", "XML/HTML Processing"),
            ("numpy", "AI/ML Computations"),
            ("opencv-python", "Computer Vision"),
            ("pytesseract", "OCR Processing"),
            ("fake-useragent", "User Agent Rotation")
        ]
        
        print("\n   üöÄ Kontrollerar revolution√§ra komponenter:")
        for module_name, description in revolutionary_imports:
            try:
                # F√∂rs√∂k importera med olika namn
                actual_module = module_name
                if module_name == "beautifulsoup4":
                    actual_module = "bs4"
                elif module_name == "opencv-python":
                    actual_module = "cv2"
                elif module_name == "fake-useragent":
                    actual_module = "fake_useragent"
                
                importlib.import_module(actual_module)
                import_validation["revolutionary_imports"][module_name] = {"status": "‚úÖ AVAILABLE", "description": description}
                import_validation["compatibility_score"] += 1
                print(f"     ‚úÖ {module_name} ({description}) - AVAILABLE")
            except ImportError:
                import_validation["revolutionary_imports"][module_name] = {"status": "‚ö†Ô∏è OPTIONAL", "description": description}
                print(f"     ‚ö†Ô∏è {module_name} ({description}) - OPTIONAL (not required)")
        
        import_validation["status"] = "completed" 
        total_imports = len(core_imports) + len(revolutionary_imports)
        import_validation["success_rate"] = (import_validation["compatibility_score"] / total_imports) * 100
        
        self.validation_results["import_dependencies"] = import_validation
        
        print(f"\nüìä Import Score: {import_validation['compatibility_score']}/{total_imports} ({import_validation['success_rate']:.1f}%)")
        print(f"‚ùå Missing Core Dependencies: {len(import_validation['missing_dependencies'])}")
        
        return import_validation
    
    def validate_configuration(self) -> Dict[str, Any]:
        """Kontrollera konfiguration och inst√§llningar"""
        print("\n‚öôÔ∏è KONTROLLERAR KONFIGURATION OCH INST√ÑLLNINGAR:")
        print("=" * 80)
        
        config_validation = {
            "status": "checking",
            "config_files": {},
            "settings_validation": {},
            "config_score": 0
        }
        
        # Kontrollera konfigurationsfiler
        config_files = [
            "requirements.txt",
            "setup.py", 
            "pyproject.toml",
            "config_template.py",
            "docker-compose.yml",
            "Makefile"
        ]
        
        for config_file in config_files:
            file_path = self.project_root / config_file
            exists = file_path.exists()
            
            if exists:
                try:
                    size = file_path.stat().st_size
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    config_validation["config_files"][config_file] = {
                        "status": "‚úÖ OK",
                        "size": size,
                        "lines": len(content.splitlines()),
                        "content_preview": content[:200] + "..." if len(content) > 200 else content
                    }
                    config_validation["config_score"] += 1
                    print(f"   ‚úÖ {config_file} - OK ({size} bytes, {len(content.splitlines())} lines)")
                    
                except Exception as e:
                    config_validation["config_files"][config_file] = {
                        "status": f"‚ö†Ô∏è WARNING: {str(e)}", 
                        "size": 0,
                        "lines": 0
                    }
                    print(f"   ‚ö†Ô∏è {config_file} - WARNING: {str(e)}")
            else:
                config_validation["config_files"][config_file] = {
                    "status": "‚ùå MISSING",
                    "size": 0,
                    "lines": 0
                }
                print(f"   ‚ùå {config_file} - MISSING")
                if config_file in ["requirements.txt", "setup.py"]:
                    self.issues_found.append(f"Missing critical config file: {config_file}")
        
        # Kontrollera SOS-specifika inst√§llningar
        sos_init = self.sos_path / "__init__.py"
        if sos_init.exists():
            try:
                with open(sos_init, 'r', encoding='utf-8') as f:
                    init_content = f.read()
                
                # Kontrollera version och metadata
                version_found = "__version__" in init_content
                title_found = "__title__" in init_content
                description_found = "__description__" in init_content
                
                config_validation["settings_validation"] = {
                    "version_defined": version_found,
                    "title_defined": title_found,
                    "description_defined": description_found,
                    "all_exported": "__all__" in init_content,
                    "imports_present": "from ." in init_content or "import" in init_content
                }
                
                settings_score = sum([version_found, title_found, description_found, "__all__" in init_content, "import" in init_content])
                config_validation["config_score"] += settings_score / 5
                
                print(f"   ‚úÖ SOS __init__.py - Settings OK ({settings_score}/5 checks passed)")
                
            except Exception as e:
                config_validation["settings_validation"] = {"error": str(e)}
                print(f"   ‚ùå SOS __init__.py - ERROR: {str(e)}")
                self.issues_found.append(f"Error reading SOS __init__.py: {str(e)}")
        
        config_validation["status"] = "completed"
        total_configs = len(config_files) + 1  # +1 for SOS settings
        config_validation["success_rate"] = (config_validation["config_score"] / total_configs) * 100
        
        self.validation_results["configuration"] = config_validation
        
        print(f"\nüìä Config Score: {config_validation['config_score']:.1f}/{total_configs} ({config_validation['success_rate']:.1f}%)")
        
        return config_validation
    
    def validate_revolutionary_components(self) -> Dict[str, Any]:
        """Kontrollera revolution√§ra komponenter"""
        print("\nüöÄ KONTROLLERAR REVOLUTION√ÑRA KOMPONENTER:")
        print("=" * 80)
        
        revolutionary_validation = {
            "status": "checking",
            "components": {},
            "integration_score": 0
        }
        
        # Kontrollera revolution√§ra filer
        revolutionary_files = [
            ("src/sos/proxy/advanced_pool.py", "Advanced Proxy Pool System"),
            ("src/sos/stealth/revolutionary_system.py", "Revolutionary Stealth Browser System"),
            ("src/sos/captcha/revolutionary_solver.py", "Revolutionary CAPTCHA Solver System")
        ]
        
        for file_path, description in revolutionary_files:
            full_path = self.project_root / file_path
            
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Analysera inneh√•ll
                    lines = len(content.splitlines())
                    size = len(content.encode('utf-8'))
                    classes = content.count('class ')
                    functions = content.count('def ')
                    async_functions = content.count('async def ')
                    
                    revolutionary_validation["components"][file_path] = {
                        "status": "‚úÖ IMPLEMENTED",
                        "description": description,
                        "size_bytes": size,
                        "lines": lines,
                        "classes": classes,
                        "functions": functions,
                        "async_functions": async_functions,
                        "complexity_score": (classes * 3 + functions * 2 + async_functions * 4) / 10
                    }
                    
                    revolutionary_validation["integration_score"] += 1
                    print(f"   ‚úÖ {description} - IMPLEMENTED")
                    print(f"     ‚îî‚îÄ {lines} lines, {classes} classes, {functions} functions, {async_functions} async")
                    
                except Exception as e:
                    revolutionary_validation["components"][file_path] = {
                        "status": f"‚ùå ERROR: {str(e)}",
                        "description": description
                    }
                    print(f"   ‚ùå {description} - ERROR: {str(e)}")
                    self.issues_found.append(f"Error in revolutionary component: {file_path} - {str(e)}")
            else:
                revolutionary_validation["components"][file_path] = {
                    "status": "‚ùå MISSING",
                    "description": description
                }
                print(f"   ‚ùå {description} - MISSING")
                self.issues_found.append(f"Missing revolutionary component: {file_path}")
        
        revolutionary_validation["status"] = "completed"
        revolutionary_validation["success_rate"] = (revolutionary_validation["integration_score"] / len(revolutionary_files)) * 100
        
        self.validation_results["revolutionary_components"] = revolutionary_validation
        
        print(f"\nüìä Revolutionary Score: {revolutionary_validation['integration_score']}/{len(revolutionary_files)} ({revolutionary_validation['success_rate']:.1f}%)")
        
        return revolutionary_validation
    
    def run_comprehensive_tests(self) -> Dict[str, Any]:
        """K√∂r omfattande tester"""
        print("\nüß™ K√òRER OMFATTANDE TESTER:")
        print("=" * 80)
        
        test_validation = {
            "status": "checking",
            "basic_import_test": {},
            "component_initialization": {},
            "functionality_test": {},
            "test_score": 0
        }
        
        # Test 1: Basic import test
        print("   üî¨ Test 1: Basic Import Test")
        try:
            sys.path.insert(0, str(self.src_path))
            import sos
            
            test_validation["basic_import_test"] = {
                "status": "‚úÖ PASSED",
                "version": getattr(sos, '__version__', 'Unknown'),
                "title": getattr(sos, '__title__', 'Unknown'),
                "components_available": len(getattr(sos, '__all__', []))
            }
            test_validation["test_score"] += 1
            print(f"     ‚úÖ SOS Import - SUCCESS (v{getattr(sos, '__version__', 'Unknown')})")
            print(f"     ‚îî‚îÄ {len(getattr(sos, '__all__', []))} components available")
            
        except Exception as e:
            test_validation["basic_import_test"] = {
                "status": f"‚ùå FAILED: {str(e)}"
            }
            print(f"     ‚ùå SOS Import - FAILED: {str(e)}")
            self.issues_found.append(f"Basic import test failed: {str(e)}")
        
        # Test 2: Component initialization
        print("\n   üèóÔ∏è Test 2: Component Initialization")
        try:
            import sos
            
            # Test get_system_info function
            system_info = sos.get_system_info()
            
            test_validation["component_initialization"] = {
                "status": "‚úÖ PASSED",
                "system_info_available": isinstance(system_info, dict),
                "components": system_info.get('components', {}),
                "frameworks": len(system_info.get('integrated_frameworks', [])),
                "capabilities": len(system_info.get('capabilities', []))
            }
            test_validation["test_score"] += 1
            print(f"     ‚úÖ System Info - SUCCESS")
            print(f"     ‚îî‚îÄ {len(system_info.get('integrated_frameworks', []))} frameworks, {len(system_info.get('capabilities', []))} capabilities")
            
        except Exception as e:
            test_validation["component_initialization"] = {
                "status": f"‚ùå FAILED: {str(e)}"
            }
            print(f"     ‚ùå Component Initialization - FAILED: {str(e)}")
            self.issues_found.append(f"Component initialization failed: {str(e)}")
        
        # Test 3: Functionality test (basic platform creation)
        print("\n   ‚öôÔ∏è Test 3: Platform Functionality")
        try:
            import sos
            
            # Test basic platform creation (without async for now)
            platform_info = sos.get_system_info()
            
            test_validation["functionality_test"] = {
                "status": "‚úÖ PASSED",
                "platform_available": True,
                "revolutionary_components": {
                    "advanced_proxy": platform_info['components'].get('advanced_proxy_pool', False),
                    "revolutionary_stealth": platform_info['components'].get('revolutionary_stealth', False),
                    "captcha_solver": platform_info['components'].get('captcha_solver', False)
                }
            }
            test_validation["test_score"] += 1
            print(f"     ‚úÖ Platform Functionality - SUCCESS")
            
            revolutionary_available = sum(test_validation["functionality_test"]["revolutionary_components"].values())
            print(f"     ‚îî‚îÄ {revolutionary_available}/3 revolutionary components available")
            
        except Exception as e:
            test_validation["functionality_test"] = {
                "status": f"‚ùå FAILED: {str(e)}"
            }
            print(f"     ‚ùå Platform Functionality - FAILED: {str(e)}")
            self.issues_found.append(f"Platform functionality test failed: {str(e)}")
        
        test_validation["status"] = "completed"
        test_validation["success_rate"] = (test_validation["test_score"] / 3) * 100
        
        self.validation_results["comprehensive_tests"] = test_validation
        
        print(f"\nüìä Test Score: {test_validation['test_score']}/3 ({test_validation['success_rate']:.1f}%)")
        
        return test_validation
    
    def generate_performance_analysis(self) -> Dict[str, Any]:
        """Generera prestandaanalys"""
        print("\n‚ö° GENERERAR PRESTANDAANALYS:")
        print("=" * 80)
        
        performance_analysis = {
            "status": "analyzing",
            "file_metrics": {},
            "code_complexity": {},
            "optimization_suggestions": [],
            "performance_score": 0
        }
        
        # Analysera filstorlekar och komplexitet
        python_files = list(self.project_root.rglob("*.py"))
        total_lines = 0
        total_files = len(python_files)
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                lines = len(content.splitlines())
                size = len(content.encode('utf-8'))
                total_lines += lines
                
                # Enkel komplexitetsanalys
                classes = content.count('class ')
                functions = content.count('def ')
                async_functions = content.count('async def ')
                imports = content.count('import ')
                
                complexity_score = (classes * 3 + functions * 2 + async_functions * 4 + imports * 0.5) / max(lines, 1)
                
                performance_analysis["file_metrics"][str(py_file.relative_to(self.project_root))] = {
                    "lines": lines,
                    "size_bytes": size,
                    "classes": classes,
                    "functions": functions,
                    "async_functions": async_functions,
                    "imports": imports,
                    "complexity_score": round(complexity_score, 2)
                }
                
                if lines > 1000:
                    performance_analysis["optimization_suggestions"].append(
                        f"Consider splitting large file: {py_file.relative_to(self.project_root)} ({lines} lines)"
                    )
                
                if complexity_score > 2.0:
                    performance_analysis["optimization_suggestions"].append(
                        f"High complexity file: {py_file.relative_to(self.project_root)} (score: {complexity_score:.2f})"
                    )
                
            except Exception as e:
                performance_analysis["file_metrics"][str(py_file.relative_to(self.project_root))] = {
                    "error": str(e)
                }
        
        # Sammanst√§ll prestationsstatistik
        performance_analysis["code_complexity"] = {
            "total_files": total_files,
            "total_lines": total_lines,
            "average_lines_per_file": round(total_lines / total_files if total_files > 0 else 0, 1),
            "large_files": len([f for f in performance_analysis["file_metrics"].values() 
                              if isinstance(f, dict) and f.get("lines", 0) > 500]),
            "complex_files": len([f for f in performance_analysis["file_metrics"].values()
                                if isinstance(f, dict) and f.get("complexity_score", 0) > 1.5])
        }
        
        # Ber√§kna prestationscore
        if total_files > 0:
            avg_complexity = sum(f.get("complexity_score", 0) for f in performance_analysis["file_metrics"].values() 
                               if isinstance(f, dict)) / total_files
            performance_analysis["performance_score"] = max(0, 100 - (avg_complexity * 20) - 
                                                          (len(performance_analysis["optimization_suggestions"]) * 5))
        else:
            performance_analysis["performance_score"] = 0
        
        performance_analysis["status"] = "completed"
        
        self.validation_results["performance_analysis"] = performance_analysis
        
        print(f"   üìä Total Files: {total_files}")
        print(f"   üìù Total Lines: {total_lines:,}")
        print(f"   üìà Average Lines/File: {performance_analysis['code_complexity']['average_lines_per_file']}")
        print(f"   üîç Large Files (>500 lines): {performance_analysis['code_complexity']['large_files']}")
        print(f"   ‚ö†Ô∏è Complex Files: {performance_analysis['code_complexity']['complex_files']}")
        print(f"   üéØ Performance Score: {performance_analysis['performance_score']:.1f}/100")
        
        if performance_analysis["optimization_suggestions"]:
            print(f"\n   üí° Optimization Suggestions ({len(performance_analysis['optimization_suggestions'])}):")
            for suggestion in performance_analysis["optimization_suggestions"][:5]:  # Show first 5
                print(f"     ‚Ä¢ {suggestion}")
        
        return performance_analysis
    
    def generate_final_report(self) -> Dict[str, Any]:
        """Generera slutlig rapport"""
        
        # Ber√§kna √∂vergripande po√§ng
        scores = []
        for validation in self.validation_results.values():
            if 'success_rate' in validation:
                scores.append(validation['success_rate'])
            elif 'performance_score' in validation:
                scores.append(validation['performance_score'])
        
        overall_score = sum(scores) / len(scores) if scores else 0
        
        # Klassificera h√§lsostatus
        if overall_score >= 90:
            health_status = "üåü EXCELLENT"
            health_color = "GREEN"
        elif overall_score >= 75:
            health_status = "‚úÖ GOOD"  
            health_color = "LIGHT_GREEN"
        elif overall_score >= 60:
            health_status = "‚ö†Ô∏è FAIR"
            health_color = "YELLOW"
        else:
            health_status = "‚ùå NEEDS_IMPROVEMENT"
            health_color = "RED"
        
        final_report = {
            "timestamp": datetime.now().isoformat(),
            "project_name": "Sparkling Owl Spin",
            "validation_summary": {
                "overall_score": round(overall_score, 1),
                "health_status": health_status,
                "health_color": health_color,
                "total_checks": sum(v.get('total_files', v.get('total_items', 1)) for v in self.validation_results.values()),
                "issues_found": len(self.issues_found),
                "recommendations": len(self.recommendations)
            },
            "detailed_results": self.validation_results,
            "issues_found": self.issues_found,
            "recommendations": self.recommendations,
            "next_steps": []
        }
        
        # Generera n√§sta steg baserat p√• resultat
        if overall_score < 100:
            final_report["next_steps"].append("Address identified issues to improve project health")
        
        if len(self.issues_found) > 0:
            final_report["next_steps"].append("Fix critical issues found during validation")
        
        if self.validation_results.get("performance_analysis", {}).get("optimization_suggestions"):
            final_report["next_steps"].append("Implement suggested performance optimizations")
        
        if not final_report["next_steps"]:
            final_report["next_steps"].append("Project is in excellent condition - ready for deployment!")
        
        return final_report
    
    def run_total_control(self) -> Dict[str, Any]:
        """K√∂r total projektkontroll"""
        
        print(f"üïí Total control started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("üéØ Running comprehensive project validation...\n")
        
        # K√∂r alla valideringar
        start_time = time.time()
        
        self.validate_file_structure()
        self.validate_code_syntax()
        self.validate_import_dependencies()
        self.validate_configuration()
        self.validate_revolutionary_components()
        self.run_comprehensive_tests()
        self.generate_performance_analysis()
        
        end_time = time.time()
        validation_time = end_time - start_time
        
        # Generera slutlig rapport
        final_report = self.generate_final_report()
        final_report["validation_time_seconds"] = round(validation_time, 2)
        
        # Visa slutresultat
        print("\n" + "="*90)
        print("üèÜ SLUTGILTIG RAPPORT - SPARKLING OWL SPIN PROJECT CONTROL")
        print("="*90)
        
        summary = final_report["validation_summary"]
        print(f"\nüìä √ñVERGRIPANDE RESULTAT:")
        print(f"   ‚Ä¢ Overall Score: {summary['overall_score']}/100")
        print(f"   ‚Ä¢ Health Status: {summary['health_status']}")
        print(f"   ‚Ä¢ Total Checks: {summary['total_checks']}")
        print(f"   ‚Ä¢ Issues Found: {summary['issues_found']}")
        print(f"   ‚Ä¢ Validation Time: {final_report['validation_time_seconds']}s")
        
        print(f"\nüéØ DETALJERADE RESULTAT:")
        for validation_name, results in self.validation_results.items():
            success_rate = results.get('success_rate', results.get('performance_score', 0))
            status_icon = "‚úÖ" if success_rate >= 80 else "‚ö†Ô∏è" if success_rate >= 60 else "‚ùå"
            print(f"   {status_icon} {validation_name.replace('_', ' ').title()}: {success_rate:.1f}%")
        
        if self.issues_found:
            print(f"\n‚ö†Ô∏è KRITISKA PROBLEM FUNNA ({len(self.issues_found)}):")
            for i, issue in enumerate(self.issues_found[:10], 1):  # Show first 10
                print(f"   {i}. {issue}")
            if len(self.issues_found) > 10:
                print(f"   ... and {len(self.issues_found) - 10} more issues")
        
        print(f"\nüéØ N√ÑSTA STEG:")
        for i, step in enumerate(final_report["next_steps"], 1):
            print(f"   {i}. {step}")
        
        print(f"\n" + "="*90)
        print(f"üîç TOTAL PROJECT CONTROL COMPLETED - {summary['health_status']}")
        print(f"üïí Validation completed in {final_report['validation_time_seconds']} seconds")
        print("="*90)
        
        # Spara detaljerad rapport
        report_path = Path("total_project_control_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ Detailed report saved to: {report_path}")
        
        return final_report

if __name__ == "__main__":
    controller = TotalProjectController()
    report = controller.run_total_control()
    
    # Final status message
    health_status = report["validation_summary"]["health_status"]
    overall_score = report["validation_summary"]["overall_score"]
    
    if overall_score >= 90:
        print(f"\nüéâ PROJECT STATUS: EXCELLENT - READY FOR ENTERPRISE DEPLOYMENT!")
    elif overall_score >= 75:
        print(f"\n‚úÖ PROJECT STATUS: GOOD - MINOR OPTIMIZATIONS RECOMMENDED")
    elif overall_score >= 60:
        print(f"\n‚ö†Ô∏è PROJECT STATUS: FAIR - IMPROVEMENTS NEEDED")
    else:
        print(f"\n‚ùå PROJECT STATUS: NEEDS SIGNIFICANT WORK")
    
    print(f"üåü Sparkling Owl Spin Total Control Completed Successfully!")
