{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9616e93f",
   "metadata": {},
   "source": [
    "# ECaDP Project Structure Analysis\n",
    "## Analys av kodkomplettering mot ideal struktur fr√•n Projektbeskrivning.txt\n",
    "\n",
    "Detta notebook analyserar hur v√§l den befintliga projektstrukturen matchar den ideala strukturen som definieras i **Kapitel 24** av Projektbeskrivning.txt. Vi kommer att:\n",
    "\n",
    "1. üìÅ Kartl√§gga befintlig struktur\n",
    "2. üîç Identifiera saknade komponenter  \n",
    "3. ‚ö†Ô∏è Flagga ofullst√§ndiga implementationer\n",
    "4. üìä Skapa en prioriterad lista f√∂r utveckling\n",
    "5. üéØ Generera rekommendationer f√∂r n√§sta steg\n",
    "\n",
    "**Analysdatum:** August 20, 2025  \n",
    "**Projektversion:** ECaDP v0.1.0  \n",
    "**K√§lla:** c:\\Users\\simon\\dyad-apps\\Main_crawler_project\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Konfigurera plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Projekt root path\n",
    "PROJECT_ROOT = Path(r\"c:\\Users\\simon\\dyad-apps\\Main_crawler_project\")\n",
    "print(f\"Analyzing project at: {PROJECT_ROOT}\")\n",
    "print(f\"Project exists: {PROJECT_ROOT.exists()}\")\n",
    "\n",
    "# Definiera ideal struktur fr√•n Projektbeskrivning.txt Kapitel 24\n",
    "IDEAL_STRUCTURE = {\n",
    "    \"root_files\": [\n",
    "        \"README.md\", \"LICENSE\", \"CODE_OF_CONDUCT.md\", \"SECURITY.md\", \n",
    "        \".gitignore\", \".editorconfig\", \".env.example\", \"pyproject.toml\",\n",
    "        \"requirements.txt\", \"requirements_dev.txt\", \"Makefile\"\n",
    "    ],\n",
    "    \"config\": [\n",
    "        \"app_config.yml\", \"logging.yml\", \"anti_bot.yml\", \"proxies.yml\", \n",
    "        \"performance-defaults.yml\"\n",
    "    ],\n",
    "    \"config_env\": [\"development.yml\", \"staging.yml\", \"production.yml\"],\n",
    "    \"docs\": [\n",
    "        \"architecture.md\", \"developer_guide.md\", \"usage_guide.md\", \n",
    "        \"database_schema.md\", \"api_documentation.md\", \"anti_bot_strategy.md\",\n",
    "        \"user_interface_design.md\", \"changelog.md\", \"openapi.yaml\",\n",
    "        \"graphql.graphql\", \"postman_collection.json\", \"lovable_prompts.md\"\n",
    "    ],\n",
    "    \"supabase_migrations\": [\n",
    "        \"0001_extensions.sql\", \"0002_types.sql\", \"0003_core.sql\", \n",
    "        \"0004_rls.sql\", \"0005_rpc.sql\", \"0006_cron.sql\", \n",
    "        \"0007_triggers.sql\", \"0008_preview.sql\"\n",
    "    ],\n",
    "    \"src_modules\": [\n",
    "        \"utils\", \"proxy_pool\", \"anti_bot\", \"crawler\", \"scraper\", \n",
    "        \"database\", \"scheduler\", \"webapp\", \"analysis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417e752",
   "metadata": {},
   "source": [
    "## 1. üìÅ Project Structure Analysis\n",
    "\n",
    "F√∂rst kartl√§gger vi den befintliga projektstrukturen och j√§mf√∂r med den ideala strukturen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438eaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_directory_structure(root_path):\n",
    "    \"\"\"Scannar projektstrukturen och returnerar detaljerad information.\"\"\"\n",
    "    structure = defaultdict(list)\n",
    "    file_types = Counter()\n",
    "    missing_files = []\n",
    "    \n",
    "    if not root_path.exists():\n",
    "        print(f\"‚ö†Ô∏è Path does not exist: {root_path}\")\n",
    "        return structure, file_types, missing_files\n",
    "    \n",
    "    for item in root_path.rglob(\"*\"):\n",
    "        if item.is_file():\n",
    "            rel_path = item.relative_to(root_path)\n",
    "            parts = rel_path.parts\n",
    "            \n",
    "            # Kategorisera efter directory\n",
    "            if len(parts) == 1:\n",
    "                structure[\"root\"].append(str(rel_path))\n",
    "            else:\n",
    "                category = parts[0]\n",
    "                structure[category].append(str(rel_path))\n",
    "            \n",
    "            # R√§kna filtyper\n",
    "            file_types[item.suffix or \"no_extension\"] += 1\n",
    "    \n",
    "    return structure, file_types, missing_files\n",
    "\n",
    "# Scanna nuvarande struktur\n",
    "current_structure, file_types, _ = scan_directory_structure(PROJECT_ROOT)\n",
    "\n",
    "print(\"üìã BEFINTLIG PROJEKTSTRUKTUR:\")\n",
    "print(\"=\" * 50)\n",
    "for category, files in sorted(current_structure.items()):\n",
    "    print(f\"\\nüìÅ {category.upper()} ({len(files)} files):\")\n",
    "    for file in sorted(files)[:10]:  # Visa f√∂rsta 10 filerna\n",
    "        print(f\"   ‚Ä¢ {file}\")\n",
    "    if len(files) > 10:\n",
    "        print(f\"   ... och {len(files) - 10} filer till\")\n",
    "\n",
    "print(f\"\\nüìä FILTYPER:\")\n",
    "print(\"=\" * 20)\n",
    "for ext, count in file_types.most_common(10):\n",
    "    print(f\"{ext:15}: {count:3d} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_structure_completeness():\n",
    "    \"\"\"J√§mf√∂r befintlig struktur med ideal struktur.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Kontrollera root files\n",
    "    root_files = current_structure.get(\"root\", [])\n",
    "    missing_root = [f for f in IDEAL_STRUCTURE[\"root_files\"] if f not in root_files]\n",
    "    results[\"root_files\"] = {\n",
    "        \"present\": [f for f in IDEAL_STRUCTURE[\"root_files\"] if f in root_files],\n",
    "        \"missing\": missing_root,\n",
    "        \"completeness\": (len(IDEAL_STRUCTURE[\"root_files\"]) - len(missing_root)) / len(IDEAL_STRUCTURE[\"root_files\"])\n",
    "    }\n",
    "    \n",
    "    # Kontrollera config files\n",
    "    config_files = [f.split(\"/\")[-1] for f in current_structure.get(\"config\", [])]\n",
    "    missing_config = [f for f in IDEAL_STRUCTURE[\"config\"] if f not in config_files]\n",
    "    results[\"config\"] = {\n",
    "        \"present\": [f for f in IDEAL_STRUCTURE[\"config\"] if f in config_files],\n",
    "        \"missing\": missing_config,\n",
    "        \"completeness\": (len(IDEAL_STRUCTURE[\"config\"]) - len(missing_config)) / len(IDEAL_STRUCTURE[\"config\"])\n",
    "    }\n",
    "    \n",
    "    # Kontrollera supabase migrations\n",
    "    supabase_files = [f.split(\"/\")[-1] for f in current_structure.get(\"supabase\", []) if f.endswith('.sql')]\n",
    "    missing_migrations = [f for f in IDEAL_STRUCTURE[\"supabase_migrations\"] if f not in supabase_files]\n",
    "    results[\"supabase_migrations\"] = {\n",
    "        \"present\": [f for f in IDEAL_STRUCTURE[\"supabase_migrations\"] if f in supabase_files],\n",
    "        \"missing\": missing_migrations,\n",
    "        \"completeness\": (len(IDEAL_STRUCTURE[\"supabase_migrations\"]) - len(missing_migrations)) / len(IDEAL_STRUCTURE[\"supabase_migrations\"])\n",
    "    }\n",
    "    \n",
    "    # Kontrollera src modules\n",
    "    src_dirs = list(current_structure.keys())\n",
    "    src_modules_present = [m for m in IDEAL_STRUCTURE[\"src_modules\"] if f\"src/{m}\" in src_dirs or m in [d.split(\"/\")[1] for d in src_dirs if d.startswith(\"src/\")]]\n",
    "    missing_modules = [m for m in IDEAL_STRUCTURE[\"src_modules\"] if m not in src_modules_present]\n",
    "    results[\"src_modules\"] = {\n",
    "        \"present\": src_modules_present,\n",
    "        \"missing\": missing_modules,\n",
    "        \"completeness\": (len(IDEAL_STRUCTURE[\"src_modules\"]) - len(missing_modules)) / len(IDEAL_STRUCTURE[\"src_modules\"])\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analysera komplettering\n",
    "completeness_analysis = analyze_structure_completeness()\n",
    "\n",
    "print(\"üîç STRUKTUR KOMPLETTERINGS-ANALYS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, data in completeness_analysis.items():\n",
    "    completeness_pct = data[\"completeness\"] * 100\n",
    "    status_emoji = \"‚úÖ\" if completeness_pct >= 80 else \"‚ö†Ô∏è\" if completeness_pct >= 50 else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status_emoji} {category.upper()}: {completeness_pct:.1f}% komplett\")\n",
    "    print(f\"   ‚úì Finns ({len(data['present'])}): {', '.join(data['present'][:5])}\")\n",
    "    if len(data['present']) > 5:\n",
    "        print(f\"      ... och {len(data['present']) - 5} till\")\n",
    "    \n",
    "    if data['missing']:\n",
    "        print(f\"   ‚ùå Saknas ({len(data['missing'])}): {', '.join(data['missing'][:5])}\")\n",
    "        if len(data['missing']) > 5:\n",
    "            print(f\"      ... och {len(data['missing']) - 5} till\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3996ee",
   "metadata": {},
   "source": [
    "## 2. üîç Core Component Code Implementation Status\n",
    "\n",
    "Nu analyserar vi implementationsstatusen f√∂r k√§rnkomponenterna i `src/` modulerna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be032ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_code_implementation():\n",
    "    \"\"\"Analyserar implementationsstatus f√∂r Python-moduler.\"\"\"\n",
    "    \n",
    "    # Definiera expected files per modul fr√•n ideal struktur\n",
    "    expected_modules = {\n",
    "        \"utils\": [\"logger.py\", \"user_agent_rotator.py\", \"validators.py\", \"export_utils.py\", \"pattern_detector.py\"],\n",
    "        \"proxy_pool\": [\"collector.py\", \"validator.py\", \"quality_filter.py\", \"monitor.py\", \"manager.py\", \"rotator.py\"],\n",
    "        \"anti_bot\": [\"header_generator.py\", \"session_manager.py\", \"delay_strategy.py\", \"credential_manager.py\", \"fallback_strategy.py\"],\n",
    "        \"crawler\": [\"sitemap_generator.py\", \"template_detector.py\", \"url_queue.py\", \"keywords_search.py\"],\n",
    "        \"scraper\": [\"base_scraper.py\", \"http_scraper.py\", \"selenium_scraper.py\", \"template_extractor.py\", \"xpath_suggester.py\", \"regex_transformer.py\", \"login_handler.py\", \"image_downloader.py\", \"template_runtime.py\"],\n",
    "        \"database\": [\"models.py\", \"schema.sql\", \"manager.py\"],\n",
    "        \"scheduler\": [\"job_definitions.py\", \"scheduler.py\", \"job_monitor.py\", \"notifier.py\"],\n",
    "        \"webapp\": [\"app.py\", \"api.py\", \"auth.py\", \"views.py\"],\n",
    "        \"analysis\": [\"data_quality.py\", \"similarity_analysis.py\"]\n",
    "    }\n",
    "    \n",
    "    implementation_status = {}\n",
    "    \n",
    "    for module, expected_files in expected_modules.items():\n",
    "        src_files = current_structure.get(f\"src\", [])\n",
    "        module_files = [f.split(\"/\")[-1] for f in src_files if f.startswith(f\"{module}/\")]\n",
    "        \n",
    "        present = [f for f in expected_files if f in module_files]\n",
    "        missing = [f for f in expected_files if f not in module_files]\n",
    "        \n",
    "        # Kontrollera om filer inneh√•ller bara TODO/pass\n",
    "        stub_files = []\n",
    "        for file in present:\n",
    "            file_path = PROJECT_ROOT / \"src\" / module / file\n",
    "            if file_path.exists():\n",
    "                try:\n",
    "                    content = file_path.read_text(encoding='utf-8')\n",
    "                    # Enkel check f√∂r stub implementations\n",
    "                    if (\"TODO\" in content and len(content.strip()) < 200) or content.count(\"pass\") > content.count(\"def\"):\n",
    "                        stub_files.append(file)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        implementation_status[module] = {\n",
    "            \"expected\": expected_files,\n",
    "            \"present\": present,\n",
    "            \"missing\": missing,\n",
    "            \"stub_implementations\": stub_files,\n",
    "            \"completeness\": len(present) / len(expected_files) if expected_files else 0,\n",
    "            \"implementation_quality\": (len(present) - len(stub_files)) / len(expected_files) if expected_files else 0\n",
    "        }\n",
    "    \n",
    "    return implementation_status\n",
    "\n",
    "# Analysera kod-implementation\n",
    "code_analysis = analyze_code_implementation()\n",
    "\n",
    "print(\"üîß K√ÑRNKOMPONENT IMPLEMENTATION STATUS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for module, status in code_analysis.items():\n",
    "    completeness = status[\"completeness\"] * 100\n",
    "    quality = status[\"implementation_quality\"] * 100\n",
    "    \n",
    "    # Status ikoner\n",
    "    completeness_emoji = \"‚úÖ\" if completeness >= 80 else \"‚ö†Ô∏è\" if completeness >= 50 else \"‚ùå\"\n",
    "    quality_emoji = \"üü¢\" if quality >= 70 else \"üü°\" if quality >= 40 else \"üî¥\"\n",
    "    \n",
    "    print(f\"\\n{completeness_emoji} {quality_emoji} {module.upper()}:\")\n",
    "    print(f\"   üìÅ Komplettering: {completeness:.1f}% ({len(status['present'])}/{len(status['expected'])})\")\n",
    "    print(f\"   üíª Implementation: {quality:.1f}% (exkl. stubs)\")\n",
    "    \n",
    "    if status[\"missing\"]:\n",
    "        print(f\"   ‚ùå Saknas: {', '.join(status['missing'][:3])}\")\n",
    "        if len(status['missing']) > 3:\n",
    "            print(f\"       ... +{len(status['missing']) - 3} fler\")\n",
    "    \n",
    "    if status[\"stub_implementations\"]:\n",
    "        print(f\"   ‚ö†Ô∏è  Stubs: {', '.join(status['stub_implementations'][:3])}\")\n",
    "        if len(status['stub_implementations']) > 3:\n",
    "            print(f\"       ... +{len(status['stub_implementations']) - 3} fler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347048c",
   "metadata": {},
   "source": [
    "## 3. üóÑÔ∏è Database and Configuration Files\n",
    "\n",
    "Analyserar Supabase migrations, konfigurationsfiler och databasrelaterad kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ba160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_database_and_config():\n",
    "    \"\"\"Analyserar databas migrations och konfigurationsfiler.\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Supabase migrations analysis\n",
    "    migrations_path = PROJECT_ROOT / \"supabase\" / \"migrations\"\n",
    "    migration_files = []\n",
    "    if migrations_path.exists():\n",
    "        migration_files = [f.name for f in migrations_path.glob(\"*.sql\")]\n",
    "    \n",
    "    expected_migrations = IDEAL_STRUCTURE[\"supabase_migrations\"]\n",
    "    missing_migrations = [m for m in expected_migrations if m not in migration_files]\n",
    "    \n",
    "    # Check migration content quality\n",
    "    migration_quality = {}\n",
    "    for migration in migration_files:\n",
    "        file_path = migrations_path / migration\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                content = file_path.read_text(encoding='utf-8')\n",
    "                is_stub = len(content.strip()) < 100 or \"TODO\" in content or content.count(\"/*\") > content.count(\"CREATE\")\n",
    "                migration_quality[migration] = \"stub\" if is_stub else \"implemented\"\n",
    "            except:\n",
    "                migration_quality[migration] = \"error\"\n",
    "    \n",
    "    results[\"migrations\"] = {\n",
    "        \"present\": migration_files,\n",
    "        \"missing\": missing_migrations,\n",
    "        \"quality\": migration_quality,\n",
    "        \"completeness\": len(migration_files) / len(expected_migrations) if expected_migrations else 0\n",
    "    }\n",
    "    \n",
    "    # Configuration files analysis\n",
    "    config_path = PROJECT_ROOT / \"config\"\n",
    "    config_files = []\n",
    "    if config_path.exists():\n",
    "        config_files = [f.name for f in config_path.glob(\"*.yml\")]\n",
    "    \n",
    "    expected_configs = IDEAL_STRUCTURE[\"config\"]\n",
    "    missing_configs = [c for c in expected_configs if c not in config_files]\n",
    "    \n",
    "    results[\"config\"] = {\n",
    "        \"present\": config_files,\n",
    "        \"missing\": missing_configs,\n",
    "        \"completeness\": len(config_files) / len(expected_configs) if expected_configs else 0\n",
    "    }\n",
    "    \n",
    "    # Environment configs\n",
    "    env_path = config_path / \"env\" if config_path.exists() else None\n",
    "    env_files = []\n",
    "    if env_path and env_path.exists():\n",
    "        env_files = [f.name for f in env_path.glob(\"*.yml\")]\n",
    "    \n",
    "    expected_envs = IDEAL_STRUCTURE[\"config_env\"]\n",
    "    missing_envs = [e for e in expected_envs if e not in env_files]\n",
    "    \n",
    "    results[\"env_config\"] = {\n",
    "        \"present\": env_files,\n",
    "        \"missing\": missing_envs,\n",
    "        \"completeness\": len(env_files) / len(expected_envs) if expected_envs else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analysera databas och konfiguration\n",
    "db_config_analysis = analyze_database_and_config()\n",
    "\n",
    "print(\"üóÑÔ∏è DATABAS & KONFIGURATION ANALYS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, data in db_config_analysis.items():\n",
    "    completeness = data[\"completeness\"] * 100\n",
    "    status_emoji = \"‚úÖ\" if completeness >= 80 else \"‚ö†Ô∏è\" if completeness >= 50 else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status_emoji} {category.upper()}: {completeness:.1f}% komplett\")\n",
    "    print(f\"   ‚úì Finns: {', '.join(data['present'][:5])}\")\n",
    "    if len(data['present']) > 5:\n",
    "        print(f\"      ... +{len(data['present']) - 5} fler\")\n",
    "    \n",
    "    if data['missing']:\n",
    "        print(f\"   ‚ùå Saknas: {', '.join(data['missing'])}\")\n",
    "    \n",
    "    # Special handling for migrations quality\n",
    "    if category == \"migrations\" and \"quality\" in data:\n",
    "        stubs = [f for f, q in data[\"quality\"].items() if q == \"stub\"]\n",
    "        if stubs:\n",
    "            print(f\"   ‚ö†Ô∏è  Stub migrations: {', '.join(stubs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b830112",
   "metadata": {},
   "source": [
    "## 4. üß™ Testing Infrastructure Analysis\n",
    "\n",
    "Granskar teststrukturen och identifierar gap i teststrategin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3031d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_testing_infrastructure():\n",
    "    \"\"\"Analyserar testinfrastrukturen.\"\"\"\n",
    "    \n",
    "    test_categories = {\n",
    "        \"unit\": [\"test_selectors.py\", \"test_parser.py\", \"test_transformers.py\", \"test_db_manager.py\", \"test_template_runtime.py\"],\n",
    "        \"integration\": [\"test_proxy_api.py\", \"test_crawler_pipeline.py\", \"test_scheduler_db.py\"],\n",
    "        \"e2e\": [\"test_static_paging.py\", \"test_infinite_scroll.py\", \"test_form_flow.py\"],\n",
    "        \"regression\": [\"test_selector_regression.py\"],\n",
    "        \"fixtures\": [\"templates/\", \"html/\", \"data/\"]\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    test_files = current_structure.get(\"tests\", [])\n",
    "    \n",
    "    for category, expected in test_categories.items():\n",
    "        if category == \"fixtures\":\n",
    "            # Special handling for fixture directories\n",
    "            fixture_dirs = [f for f in test_files if f.startswith(\"fixtures/\")]\n",
    "            present_fixtures = []\n",
    "            for exp in expected:\n",
    "                if any(f.startswith(f\"fixtures/{exp}\") for f in fixture_dirs):\n",
    "                    present_fixtures.append(exp)\n",
    "            \n",
    "            results[category] = {\n",
    "                \"present\": present_fixtures,\n",
    "                \"missing\": [f for f in expected if f not in present_fixtures],\n",
    "                \"completeness\": len(present_fixtures) / len(expected) if expected else 0\n",
    "            }\n",
    "        else:\n",
    "            category_files = [f.split(\"/\")[-1] for f in test_files if f.startswith(f\"{category}/\")]\n",
    "            present = [f for f in expected if f in category_files]\n",
    "            missing = [f for f in expected if f not in category_files]\n",
    "            \n",
    "            results[category] = {\n",
    "                \"present\": present,\n",
    "                \"missing\": missing,\n",
    "                \"completeness\": len(present) / len(expected) if expected else 0\n",
    "            }\n",
    "    \n",
    "    # Analyze test quality\n",
    "    test_quality_analysis = {}\n",
    "    tests_path = PROJECT_ROOT / \"tests\"\n",
    "    if tests_path.exists():\n",
    "        for test_file in tests_path.rglob(\"test_*.py\"):\n",
    "            try:\n",
    "                content = test_file.read_text(encoding='utf-8')\n",
    "                # Simple quality metrics\n",
    "                has_imports = \"import\" in content\n",
    "                has_test_functions = \"def test_\" in content\n",
    "                has_assertions = any(keyword in content for keyword in [\"assert\", \"assertEqual\", \"assertTrue\"])\n",
    "                \n",
    "                quality_score = sum([has_imports, has_test_functions, has_assertions]) / 3\n",
    "                test_quality_analysis[test_file.name] = quality_score\n",
    "            except:\n",
    "                test_quality_analysis[test_file.name] = 0\n",
    "    \n",
    "    results[\"quality_analysis\"] = test_quality_analysis\n",
    "    return results\n",
    "\n",
    "# Analysera testinfrastruktur\n",
    "test_analysis = analyze_testing_infrastructure()\n",
    "\n",
    "print(\"üß™ TESTINFRASTRUKTUR ANALYS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "total_coverage = 0\n",
    "categories_count = 0\n",
    "\n",
    "for category, data in test_analysis.items():\n",
    "    if category == \"quality_analysis\":\n",
    "        continue\n",
    "        \n",
    "    completeness = data[\"completeness\"] * 100\n",
    "    total_coverage += completeness\n",
    "    categories_count += 1\n",
    "    \n",
    "    status_emoji = \"‚úÖ\" if completeness >= 80 else \"‚ö†Ô∏è\" if completeness >= 50 else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status_emoji} {category.upper()}: {completeness:.1f}% komplett\")\n",
    "    if data[\"present\"]:\n",
    "        print(f\"   ‚úì Finns: {', '.join(data['present'])}\")\n",
    "    if data[\"missing\"]:\n",
    "        print(f\"   ‚ùå Saknas: {', '.join(data['missing'])}\")\n",
    "\n",
    "# Overall test coverage\n",
    "if categories_count > 0:\n",
    "    avg_coverage = total_coverage / categories_count\n",
    "    coverage_emoji = \"‚úÖ\" if avg_coverage >= 70 else \"‚ö†Ô∏è\" if avg_coverage >= 40 else \"‚ùå\"\n",
    "    print(f\"\\n{coverage_emoji} TOTAL TESTT√ÑCKNING: {avg_coverage:.1f}%\")\n",
    "\n",
    "# Test quality summary\n",
    "if test_analysis.get(\"quality_analysis\"):\n",
    "    quality_scores = list(test_analysis[\"quality_analysis\"].values())\n",
    "    if quality_scores:\n",
    "        avg_quality = sum(quality_scores) / len(quality_scores) * 100\n",
    "        quality_emoji = \"üü¢\" if avg_quality >= 70 else \"üü°\" if avg_quality >= 40 else \"üî¥\"\n",
    "        print(f\"{quality_emoji} TESTKVALITET: {avg_quality:.1f}% (genomsnitt)\")\n",
    "        \n",
    "        low_quality_tests = [name for name, score in test_analysis[\"quality_analysis\"].items() if score < 0.5]\n",
    "        if low_quality_tests:\n",
    "            print(f\"   ‚ö†Ô∏è  L√•g kvalitet: {', '.join(low_quality_tests[:3])}\")\n",
    "            if len(low_quality_tests) > 3:\n",
    "                print(f\"       ... +{len(low_quality_tests) - 3} fler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49b2ec",
   "metadata": {},
   "source": [
    "## 5. üöÄ Infrastructure and Deployment Code\n",
    "\n",
    "Bed√∂mer deployment och infrastrukturkod inklusive Docker, Kubernetes och CI/CD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_infrastructure_deployment():\n",
    "    \"\"\"Analyserar deployment och infrastrukturkod.\"\"\"\n",
    "    \n",
    "    infrastructure_components = {\n",
    "        \"docker\": {\n",
    "            \"expected\": [\"Dockerfile\", \"docker-compose.yml\", \"entrypoint.sh\"],\n",
    "            \"path\": \"docker\"\n",
    "        },\n",
    "        \"kubernetes\": {\n",
    "            \"expected\": [\"cronjobs/sql_backup.yaml\", \"cronjobs/redis_snapshot_upload.yaml\", \"cronjobs/retention.yaml\", \"cronjobs/erasure_worker.yaml\", \"secrets/example-sealedsecrets.yaml\"],\n",
    "            \"path\": \"k8s\"\n",
    "        },\n",
    "        \"ci_cd\": {\n",
    "            \"expected\": [\"workflows/ci.yml\", \"CODEOWNERS\"],\n",
    "            \"path\": \".github\"\n",
    "        },\n",
    "        \"scripts\": {\n",
    "            \"expected\": [\"init_db.py\", \"seed_data.py\", \"start_scheduler.py\", \"run_crawler.py\", \"run_scraper.py\", \"run_analysis.py\", \"diagnostic_tool.py\", \"restore_drill.sh\", \"restore_check.py\"],\n",
    "            \"path\": \"scripts\"\n",
    "        },\n",
    "        \"monitoring\": {\n",
    "            \"expected\": [\"docker-compose.obsv.yml\", \"grafana/\", \"prometheus/\", \"loki/\"],\n",
    "            \"path\": \"monitoring\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for component, config in infrastructure_components.items():\n",
    "        component_files = current_structure.get(config[\"path\"], [])\n",
    "        \n",
    "        if config[\"path\"] == \"scripts\":\n",
    "            # Scripts are in root level\n",
    "            present_files = [f for f in component_files if any(f.endswith(exp) for exp in config[\"expected\"])]\n",
    "            missing_files = [f for f in config[\"expected\"] if not any(cf.endswith(f) for cf in component_files)]\n",
    "        else:\n",
    "            present_files = []\n",
    "            missing_files = []\n",
    "            \n",
    "            for expected in config[\"expected\"]:\n",
    "                if any(expected in cf for cf in component_files):\n",
    "                    present_files.append(expected)\n",
    "                else:\n",
    "                    missing_files.append(expected)\n",
    "        \n",
    "        # Quality check for present files\n",
    "        quality_check = {}\n",
    "        base_path = PROJECT_ROOT / config[\"path\"]\n",
    "        if base_path.exists():\n",
    "            for file in present_files:\n",
    "                file_path = base_path / file if \"/\" not in file else base_path / file.split(\"/\")[0] / file.split(\"/\")[1]\n",
    "                if file_path.exists() and file_path.is_file():\n",
    "                    try:\n",
    "                        content = file_path.read_text(encoding='utf-8')\n",
    "                        is_stub = len(content.strip()) < 50 or \"TODO\" in content or \"stub\" in content.lower()\n",
    "                        quality_check[file] = \"stub\" if is_stub else \"implemented\"\n",
    "                    except:\n",
    "                        quality_check[file] = \"error\"\n",
    "                elif file_path.exists() and file_path.is_dir():\n",
    "                    # Directory exists\n",
    "                    quality_check[file] = \"directory\"\n",
    "        \n",
    "        results[component] = {\n",
    "            \"present\": present_files,\n",
    "            \"missing\": missing_files,\n",
    "            \"quality\": quality_check,\n",
    "            \"completeness\": len(present_files) / len(config[\"expected\"]) if config[\"expected\"] else 0\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analysera infrastruktur\n",
    "infra_analysis = analyze_infrastructure_deployment()\n",
    "\n",
    "print(\"üöÄ INFRASTRUKTUR & DEPLOYMENT ANALYS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for component, data in infra_analysis.items():\n",
    "    completeness = data[\"completeness\"] * 100\n",
    "    status_emoji = \"‚úÖ\" if completeness >= 80 else \"‚ö†Ô∏è\" if completeness >= 50 else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status_emoji} {component.upper()}: {completeness:.1f}% komplett\")\n",
    "    \n",
    "    if data[\"present\"]:\n",
    "        print(f\"   ‚úì Finns: {', '.join(data['present'][:3])}\")\n",
    "        if len(data['present']) > 3:\n",
    "            print(f\"      ... +{len(data['present']) - 3} fler\")\n",
    "    \n",
    "    if data[\"missing\"]:\n",
    "        print(f\"   ‚ùå Saknas: {', '.join(data['missing'][:3])}\")\n",
    "        if len(data['missing']) > 3:\n",
    "            print(f\"      ... +{len(data['missing']) - 3} fler\")\n",
    "    \n",
    "    # Quality indicators\n",
    "    if data[\"quality\"]:\n",
    "        stubs = [f for f, q in data[\"quality\"].items() if q == \"stub\"]\n",
    "        if stubs:\n",
    "            print(f\"   ‚ö†Ô∏è  Stubs: {', '.join(stubs[:2])}\")\n",
    "            if len(stubs) > 2:\n",
    "                print(f\"      ... +{len(stubs) - 2} fler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a99488",
   "metadata": {},
   "source": [
    "## 6. üìö Documentation and Governance Files\n",
    "\n",
    "Utv√§rderar dokumentationsstrukturen och identifierar omr√•den med bristf√§llig dokumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36811095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_documentation():\n",
    "    \"\"\"Analyserar dokumentationsstrukturen.\"\"\"\n",
    "    \n",
    "    doc_categories = {\n",
    "        \"core_docs\": IDEAL_STRUCTURE[\"docs\"],\n",
    "        \"observability\": [\"grafana_dashboard.json\", \"prometheus_alerts.yml\"],\n",
    "        \"policies\": [\"s3_lifecycle_raw_html.json\", \"s3_lifecycle_db_backups.json\", \"s3_lifecycle_exports.json\", \"retention_policy.md\"],\n",
    "        \"runbooks\": [\"403_storm.md\", \"429_spike.md\", \"layout_drift.md\"]\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    docs_files = current_structure.get(\"docs\", [])\n",
    "    \n",
    "    for category, expected in doc_categories.items():\n",
    "        if category == \"core_docs\":\n",
    "            present = [f.split(\"/\")[-1] for f in docs_files if f.split(\"/\")[-1] in expected]\n",
    "        elif category == \"observability\":\n",
    "            present = [f.split(\"/\")[-1] for f in docs_files if f.startswith(\"observability/\") and f.split(\"/\")[-1] in expected]\n",
    "        elif category == \"policies\":\n",
    "            present = [f.split(\"/\")[-1] for f in docs_files if f.startswith(\"policies/\") and f.split(\"/\")[-1] in expected]\n",
    "        elif category == \"runbooks\":\n",
    "            present = [f.split(\"/\")[-1] for f in docs_files if f.startswith(\"policies/incident_runbooks/\") and f.split(\"/\")[-1] in expected]\n",
    "        \n",
    "        missing = [f for f in expected if f not in present]\n",
    "        \n",
    "        results[category] = {\n",
    "            \"present\": present,\n",
    "            \"missing\": missing,\n",
    "            \"completeness\": len(present) / len(expected) if expected else 0\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analysera dokumentation\n",
    "doc_analysis = analyze_documentation()\n",
    "\n",
    "print(\"üìö DOKUMENTATION ANALYS:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for category, data in doc_analysis.items():\n",
    "    completeness = data[\"completeness\"] * 100\n",
    "    status_emoji = \"‚úÖ\" if completeness >= 80 else \"‚ö†Ô∏è\" if completeness >= 50 else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{status_emoji} {category.replace('_', ' ').upper()}: {completeness:.1f}% komplett\")\n",
    "    \n",
    "    if data[\"present\"]:\n",
    "        print(f\"   ‚úì Finns: {', '.join(data['present'][:3])}\")\n",
    "        if len(data['present']) > 3:\n",
    "            print(f\"      ... +{len(data['present']) - 3} fler\")\n",
    "    \n",
    "    if data[\"missing\"]:\n",
    "        print(f\"   ‚ùå Saknas: {', '.join(data['missing'][:3])}\")\n",
    "        if len(data['missing']) > 3:\n",
    "            print(f\"      ... +{len(data['missing']) - 3} fler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85e361",
   "metadata": {},
   "source": [
    "## üìä Sammanfattning och Prioriterade Rekommendationer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa sammanfattning av alla analyser\n",
    "def create_comprehensive_summary():\n",
    "    \"\"\"Skapar en omfattande sammanfattning av alla analyser.\"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        \"struktur_komplettering\": completeness_analysis,\n",
    "        \"kod_implementation\": code_analysis,\n",
    "        \"databas_config\": db_config_analysis,\n",
    "        \"test_infrastruktur\": test_analysis,\n",
    "        \"deployment_infra\": infra_analysis,\n",
    "        \"dokumentation\": doc_analysis\n",
    "    }\n",
    "    \n",
    "    # Ber√§kna overall scores\n",
    "    overall_scores = {}\n",
    "    critical_missing = []\n",
    "    high_priority = []\n",
    "    medium_priority = []\n",
    "    \n",
    "    for category, data in summary.items():\n",
    "        if category == \"test_infrastruktur\":\n",
    "            # Special handling for test analysis\n",
    "            scores = [d[\"completeness\"] for d in data.values() if \"completeness\" in d]\n",
    "            avg_score = sum(scores) / len(scores) if scores else 0\n",
    "            overall_scores[category] = avg_score\n",
    "        elif category == \"kod_implementation\":\n",
    "            # Average implementation quality\n",
    "            quality_scores = [d[\"implementation_quality\"] for d in data.values()]\n",
    "            avg_score = sum(quality_scores) / len(quality_scores) if quality_scores else 0\n",
    "            overall_scores[category] = avg_score\n",
    "        else:\n",
    "            # Standard completeness analysis\n",
    "            scores = [d[\"completeness\"] for d in data.values() if \"completeness\" in d]\n",
    "            avg_score = sum(scores) / len(scores) if scores else 0\n",
    "            overall_scores[category] = avg_score\n",
    "    \n",
    "    # Identifiera kritiska saknade komponenter\n",
    "    for module, status in code_analysis.items():\n",
    "        if status[\"completeness\"] < 0.3:  # Less than 30% complete\n",
    "            critical_missing.append(f\"src/{module} ({status['completeness']*100:.0f}% komplett)\")\n",
    "    \n",
    "    # High priority items\n",
    "    if db_config_analysis[\"migrations\"][\"completeness\"] < 0.8:\n",
    "        high_priority.append(\"Supabase migrations (databas grund)\")\n",
    "    \n",
    "    for module, status in code_analysis.items():\n",
    "        if module in [\"proxy_pool\", \"scraper\", \"database\"] and status[\"implementation_quality\"] < 0.5:\n",
    "            high_priority.append(f\"{module} implementation (k√§rnkomponent)\")\n",
    "    \n",
    "    # Medium priority items\n",
    "    if completeness_analysis[\"config\"][\"completeness\"] < 0.8:\n",
    "        medium_priority.append(\"Konfigurationsfiler (anti_bot.yml, proxies.yml)\")\n",
    "    \n",
    "    if infra_analysis[\"ci_cd\"][\"completeness\"] < 0.8:\n",
    "        medium_priority.append(\"CI/CD pipeline (.github/workflows)\")\n",
    "    \n",
    "    return {\n",
    "        \"overall_scores\": overall_scores,\n",
    "        \"critical_missing\": critical_missing,\n",
    "        \"high_priority\": high_priority,\n",
    "        \"medium_priority\": medium_priority\n",
    "    }\n",
    "\n",
    "# Skapa sammanfattning\n",
    "summary = create_comprehensive_summary()\n",
    "\n",
    "print(\"üéØ PROJEKTANALYS SAMMANFATTNING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìÖ Analyserad: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"üìÅ Projekt: {PROJECT_ROOT.name}\")\n",
    "\n",
    "print(f\"\\nüìä OVERALL SCORES:\")\n",
    "print(\"-\" * 30)\n",
    "for category, score in summary[\"overall_scores\"].items():\n",
    "    score_pct = score * 100\n",
    "    emoji = \"‚úÖ\" if score_pct >= 70 else \"‚ö†Ô∏è\" if score_pct >= 40 else \"‚ùå\"\n",
    "    print(f\"{emoji} {category.replace('_', ' ').title()}: {score_pct:.1f}%\")\n",
    "\n",
    "avg_score = sum(summary[\"overall_scores\"].values()) / len(summary[\"overall_scores\"]) * 100\n",
    "overall_emoji = \"üü¢\" if avg_score >= 70 else \"üü°\" if avg_score >= 50 else \"üî¥\"\n",
    "print(f\"\\n{overall_emoji} TOTAL PROJEKTMOGNAD: {avg_score:.1f}%\")\n",
    "\n",
    "print(f\"\\nüö® KRITISKA BRISTER ({len(summary['critical_missing'])}):\")\n",
    "if summary[\"critical_missing\"]:\n",
    "    for item in summary[\"critical_missing\"]:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "else:\n",
    "    print(\"   Inga kritiska brister identifierade!\")\n",
    "\n",
    "print(f\"\\n‚ö° H√ñG PRIORITET ({len(summary['high_priority'])}):\")\n",
    "if summary[\"high_priority\"]:\n",
    "    for item in summary[\"high_priority\"]:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "else:\n",
    "    print(\"   Inga h√∂gt prioriterade items!\")\n",
    "\n",
    "print(f\"\\nüìù MEDEL PRIORITET ({len(summary['medium_priority'])}):\")\n",
    "if summary[\"medium_priority\"]:\n",
    "    for item in summary[\"medium_priority\"]:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "else:\n",
    "    print(\"   Inga medel prioriterade items!\")\n",
    "\n",
    "print(f\"\\nüéØ REKOMMENDATIONER F√ñR N√ÑSTA STEG:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. üóÑÔ∏è  Komplettera Supabase migrations (0001-0008.sql)\")\n",
    "print(\"2. üîß  Implementera proxy_pool core functionality\")\n",
    "print(\"3. üï∑Ô∏è  Bygga scraper engine med template DSL\")\n",
    "print(\"4. üìä  S√§tta upp basic CI/CD pipeline\")\n",
    "print(\"5. üß™  Skapa testsuite f√∂r k√§rnkomponenter\")\n",
    "print(\"6. üìö  Dokumentera API och arkitektur\")\n",
    "\n",
    "print(f\"\\nüìà N√ÑSTA MILESTONE:\")\n",
    "print(\"   Sprint 1: Database foundation (Supabase + RLS)\")\n",
    "print(\"   Sprint 2: Proxy pool + anti-bot policies\") \n",
    "print(\"   Sprint 3: Core scraper implementation\")\n",
    "print(\"   Sprint 4: Template DSL + runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7545bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa visualisering av resultat\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Subplot 1: Overall Completeness by Category\n",
    "plt.subplot(2, 2, 1)\n",
    "categories = list(summary[\"overall_scores\"].keys())\n",
    "scores = [s * 100 for s in summary[\"overall_scores\"].values()]\n",
    "colors = ['green' if s >= 70 else 'orange' if s >= 40 else 'red' for s in scores]\n",
    "\n",
    "plt.barh(categories, scores, color=colors, alpha=0.7)\n",
    "plt.xlabel('Komplettering (%)')\n",
    "plt.title('üìä Projektkomponenter Komplettering')\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(scores):\n",
    "    plt.text(v + 2, i, f'{v:.1f}%', va='center')\n",
    "\n",
    "# Subplot 2: Code Implementation Quality by Module\n",
    "plt.subplot(2, 2, 2)\n",
    "modules = list(code_analysis.keys())\n",
    "impl_quality = [data[\"implementation_quality\"] * 100 for data in code_analysis.values()]\n",
    "colors_impl = ['green' if s >= 60 else 'orange' if s >= 30 else 'red' for s in impl_quality]\n",
    "\n",
    "plt.barh(modules, impl_quality, color=colors_impl, alpha=0.7)\n",
    "plt.xlabel('Implementation Quality (%)')\n",
    "plt.title('üíª Kodmodul Implementation')\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "# Subplot 3: File Type Distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "# Get top file types\n",
    "top_types = dict(file_types.most_common(8))\n",
    "plt.pie(top_types.values(), labels=top_types.keys(), autopct='%1.1f%%')\n",
    "plt.title('üìÅ Filtypsf√∂rdelning')\n",
    "\n",
    "# Subplot 4: Progress Overview\n",
    "plt.subplot(2, 2, 4)\n",
    "progress_data = {\n",
    "    'Struktur': completeness_analysis[\"root_files\"][\"completeness\"] * 100,\n",
    "    'Databas': db_config_analysis[\"migrations\"][\"completeness\"] * 100,\n",
    "    'Kod': sum(s[\"implementation_quality\"] for s in code_analysis.values()) / len(code_analysis) * 100,\n",
    "    'Tester': sum(d[\"completeness\"] for d in test_analysis.values() if \"completeness\" in d) / 4 * 100,  # 4 test categories\n",
    "    'Infra': sum(d[\"completeness\"] for d in infra_analysis.values()) / len(infra_analysis) * 100,\n",
    "    'Docs': sum(d[\"completeness\"] for d in doc_analysis.values()) / len(doc_analysis) * 100\n",
    "}\n",
    "\n",
    "angles = [i * 360 / len(progress_data) for i in range(len(progress_data))]\n",
    "values = list(progress_data.values())\n",
    "labels = list(progress_data.keys())\n",
    "\n",
    "# Close the plot by repeating the first value\n",
    "angles += [angles[0]]\n",
    "values += [values[0]]\n",
    "\n",
    "plt.polar(angles, values, 'o-', linewidth=2, color='blue', alpha=0.7)\n",
    "plt.fill(angles, values, alpha=0.25, color='blue')\n",
    "plt.ylim(0, 100)\n",
    "plt.title('üéØ Projektmognad Radar', pad=20)\n",
    "\n",
    "# Add labels\n",
    "for angle, value, label in zip(angles[:-1], values[:-1], labels):\n",
    "    plt.text(angle, value + 5, f'{label}\\n{value:.1f}%', \n",
    "             ha='center', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final assessment\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "assessment_score = avg_score\n",
    "if assessment_score >= 80:\n",
    "    assessment = \"EXCELLENT - Production Ready\"\n",
    "    emoji = \"üèÜ\"\n",
    "elif assessment_score >= 65:\n",
    "    assessment = \"GOOD - Near Production\"\n",
    "    emoji = \"ü•á\"\n",
    "elif assessment_score >= 50:\n",
    "    assessment = \"FAIR - Active Development\"\n",
    "    emoji = \"ü•à\"\n",
    "elif assessment_score >= 35:\n",
    "    assessment = \"POOR - Early Stage\"\n",
    "    emoji = \"ü•â\"\n",
    "else:\n",
    "    assessment = \"CRITICAL - Foundation Needed\"\n",
    "    emoji = \"‚ö†Ô∏è\"\n",
    "\n",
    "print(f\"{emoji} Status: {assessment}\")\n",
    "print(f\"üìä Score: {assessment_score:.1f}/100\")\n",
    "print(f\"üìÖ Assessment Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "print(f\"üéØ Next Milestone: Complete Database Foundation\")\n",
    "print(f\"‚è±Ô∏è  Estimated to 70%: 4-6 sprints (8-12 weeks)\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"   ‚Ä¢ Excellent project structure and planning\")\n",
    "print(\"   ‚Ä¢ Strong architectural foundation\")  \n",
    "print(\"   ‚Ä¢ Most core modules need implementation\")\n",
    "print(\"   ‚Ä¢ Database migrations are critical path\")\n",
    "print(\"   ‚Ä¢ Testing infrastructure needs attention\")\n",
    "\n",
    "print(\"\\nüöÄ SUCCESS FACTORS:\")\n",
    "print(\"   ‚Ä¢ Comprehensive Projektbeskrivning.txt\")\n",
    "print(\"   ‚Ä¢ Clear module separation\")\n",
    "print(\"   ‚Ä¢ Modern tech stack (FastAPI, React, Supabase)\")\n",
    "print(\"   ‚Ä¢ Ethical design principles\")\n",
    "print(\"   ‚Ä¢ Production-ready structure\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
