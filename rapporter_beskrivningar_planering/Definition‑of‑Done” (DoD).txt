# Master‑checklista för sparkling‑owl‑spin – Release‑klar 1.0

> **Hur du använder listan**: Varje del börjar med en kort, enkel förklaring. Sedan följer *exakta kommandon*, *vad som ska hända*, och *hur du verifierar*. Kryssa i punkter allt eftersom. Windows‑kommandon visas först; macOS/Linux anges där det skiljer.

---

## A) Grundförutsättningar & miljö

**Enkelt:** Vi säkerställer att rätt verktyg finns (Python, Docker, Node, Git) och att versionerna är kompatibla.

**Gör så här**

* [ ] Installera **Python ≥ 3.11**, **Docker Desktop** (med Compose), **Node.js LTS + npm**, **Git**, **VS Code**.
* [ ] Verifiera versioner:

  * Windows PowerShell:

    ```powershell
    python --version
    docker --version
    docker compose version
    node --version
    npm --version
    git --version
    code --version
    ```
  * macOS/Linux:

    ```bash
    python3 --version
    docker --version
    docker compose version
    node --version
    npm --version
    git --version
    code --version
    ```

**Förväntat:** Kommandon visar versionsnummer (inga fel).
**Om fel:** Installera/uppgradera via respektive officiell installatör.

---

## B) Repo, struktur och basfiler

**Enkelt:** Klona projektet och säkerställ att trädstrukturen finns.

**Gör så här**

* [ ] Klona:

  ```powershell
  git clone https://github.com/sax3l/sparkling-owl-spin.git
  cd sparkling-owl-spin
  ```
* [ ] Lista trädet (översikt):

  ```powershell
  git ls-files
  ```

**Förväntat:** Projektmappar som `src/`, `frontend/`, `config/`, `docker/`, `supabase/`, `tests/` syns.
**Verifiera:** Att README.md finns och beskriver startkommandon.

---

## C) Miljöfiler & hemligheter

**Enkelt:** `.env` sätter lokala konfigvärden; `.env.example` är mallen. Aldrig checka in hemligheter.

**Gör så här**

* [ ] Skapa lokal `.env` från mall:

  ```powershell
  Copy-Item .env.example .env
  # macOS/Linux: cp .env.example .env
  ```
* [ ] Fyll i nycklar: `SUPABASE_URL`, `SUPABASE_ANON_KEY`, `SUPABASE_SERVICE_ROLE`, `DATABASE_URL`, `JWT_SECRET`, `REDIS_URL`, ev. `GCP_*` för export.
* [ ] (Valfritt) Använd OS‑nyckelring/direnv:

  * direnv (macOS/Linux):

    ```bash
    brew install direnv # macOS
    echo 'use dotenv' > .envrc
    direnv allow
    ```

**Förväntat:** Applikationerna läser konfig från `.env`.
**Verifiera:** Startkommandon (senare avsnitt) hämtar rätt värden utan fel.

---

## D) Python‑miljö & backend‑beroenden

**Enkelt:** Vi skapar virtuell miljö och installerar paket.

**Gör så här**

* [ ] Skapa venv & installera:

  ```powershell
  python -m venv .venv
  . .venv\Scripts\Activate.ps1
  pip install -U pip wheel
  make install-dev
  ```

  *macOS/Linux:*

  ```bash
  python3 -m venv .venv
  source .venv/bin/activate
  pip install -U pip wheel
  make install-dev
  ```

**Förväntat:** Alla Python‑paket installeras (FastAPI/Playwright/SQLAlchemy m.fl.).
**Verifiera:** `pip list` visar paket, inga build‑fel.

---

## E) Frontend‑miljö (React/Vite) & beroenden

**Enkelt:** Installera npm‑paket för UI, dev‑server, bygg.

**Gör så här**

* [ ] Installera:

  ```powershell
  cd frontend
  npm ci || npm install
  cd ..
  ```

**Förväntat:** `node_modules/` skapas, inga audit‑fel blockerar.
**Verifiera:** `npm run dev` (senare) startar dev‑servern utan fel.

---

## F) Lokala tjänster via Docker (syntetiska testsajter m.m.)

**Enkelt:** Starta helper‑tjänster (syntetiska sidor för E2E‑tester: statisk lista, oändlig scroll, formulärflöde).

**Gör så här**

* [ ] Starta:

  ```powershell
  make docker-up
  ```
* [ ] Öppna i webbläsare:
  `http://localhost:8081` (statisk), `http://localhost:8082` (infinite scroll), `http://localhost:8083` (form)
* [ ] Stoppa:

  ```powershell
  make docker-down
  ```

**Förväntat:** Tre tjänster svarar; sidorna laddar.
**Verifiera:** HTTP 200 i webbläsaren.

---

## G) Databas & Supabase

**Enkelt:** Kör migrations lokalt (PostgreSQL i Docker). Samma SQL ska kunna köras i Supabase.

**Gör så här**

* [ ] Starta lokal Postgres (om compose ingår):

  ```powershell
  docker compose up -d db
  ```
* [ ] Kör Alembic/SQL migrations:

  ```powershell
  make db-migrate
  ```
* [ ] Supabase (variant B): Klistra in `supabase/migrations/*.sql` i **Supabase Studio → SQL editor** och kör i ordning.
  **Förväntat:** Tabeller, index, RLS‑regler skapade.
  **Verifiera:**

  * Supabase Studio → Tables visar `jobs`, `results`, `templates`, `proxies`, `dq_metrics` m.fl.
  * `SELECT 1;` fungerar, ingen RLS‑block på service‑key.

---

## H) API (REST & GraphQL)

**Enkelt:** Starta FastAPI‑servern, kolla OpenAPI och GraphQL.

**Gör så här**

* [ ] Starta API:

  ```powershell
  make run-api
  ```
* [ ] Öppna: `http://localhost:8000/docs` (OpenAPI) och `http://localhost:8000/graphql` (playground).
* [ ] Testa med curl:

  ```powershell
  curl http://localhost:8000/health
  curl http://localhost:8000/api/jobs
  ```

**Förväntat:** `/health` → `{status: "ok"}`. Jobb‑endpoints svarar.
**Verifiera:** 200‑svar och loggar i terminalen.

---

## I) Frontend (SSR/SPA), auth & miljökoppling

**Enkelt:** Dev‑server startas; frontend pratar med backend via env/proxy. Supabase Auth kopplas.

**Gör så här**

* [ ] Starta dev‑server:

  ```powershell
  cd frontend
  npm run dev
  ```
* [ ] Öppna: `http://localhost:5173` (standard Vite‑port).
* [ ] Sätt `VITE_API_URL` och `VITE_SUPABASE_URL/KEY` i `frontend/.env.local`.
  **Förväntat:** UI laddar; inloggning fungerar mot Supabase (lokalt eller moln).
  **Verifiera:** Du kan lista jobb, skapa mallar, se dashboards.

---

## J) Scraper/Crawler‑kärna

**Enkelt:** Motorerna för crawl, rendering (Playwright), extraktion (CSS/XPath), mall‑DSL och policyer fungerar.

**Gör så här**

* [ ] Diagnostik (torrkörning):

  ```powershell
  python scripts/diagnostic_tool.py --url http://localhost:8081
  ```
* [ ] Kör crawler på syntetisk sajt:

  ```powershell
  python scripts/run_crawler.py --seed http://localhost:8081 --depth 2
  ```
* [ ] Kör scraper med mall:

  ```powershell
  python scripts/run_scraper.py --url http://localhost:8081/items/1 --template data/templates/example_detail.yml
  ```

**Förväntat:** Sitemap skapas; data extraheras enligt mall; JSON lagras.
**Verifiera:** Rader i `results`‑tabell, sparade filer i `data/`.

---

## K) Proxy‑pool & åtkomstpolicyer (laglig drift)

**Enkelt:** Proxyhantering, rate‑limits och domänpolicyer är konfigurerade. Inga förbjudna bypass‑steg.

**Gör så här**

* [ ] Fyll `config/proxies.yml` med betrodd leverantör.
* [ ] Sätt per‑domän policy i `config/domain_policies.yml` (RPS, timeouts, user‑agent‑profil).
* [ ] Starta proxy‑API (om separat tjänst):

  ```powershell
  python -m src.proxy_pool.api.server
  ```

**Förväntat:** Jobb använder roterande/sticky proxy enligt policy.
**Verifiera:** Loggar visar proxy‑ID och latens; inga 403/429‑spikar.

---

## L) Jobbschemaläggning

**Enkelt:** Återkommande crawl/scrape körs via scheduler och köer.

**Gör så här**

* [ ] Starta scheduler:

  ```powershell
  python scripts/start_scheduler.py
  ```
* [ ] Skapa jobb via API/GUI (cron/interval).
  **Förväntat:** Jobb startar med rätt prioritet och concurrency.
  **Verifiera:** Dashboard för ködjup, slutförda/failed jobs.

---

## M) Exporter & koppling till GCP

**Enkelt:** Data kan exporteras till CSV/JSON och pushas till **BigQuery**/**GCS**.

**Gör så här**

* [ ] Sätt `GCP_PROJECT`, `GCP_KEYFILE` (service account json), `BQ_DATASET` i `.env`.
* [ ] Testa exporter:

  ```powershell
  python -m src.exporters.csv_exporter --query "SELECT * FROM results LIMIT 10" --out data/exports/sample.csv
  python -m src.exporters.bigquery_exporter --table results --dataset ${env:BQ_DATASET}
  ```

**Förväntat:** CSV skrivs; BigQuery‑tabell fylls.
**Verifiera:** `bq ls` visar tabell; rader finns i BigQuery UI.

---

## N) Observability (Prometheus/Grafana)

**Enkelt:** Metrik och dashboards visar hälsa (RPS, fel, proxyhälsa, P95, köer).

**Gör så här**

* [ ] Starta lokala stacken (om compose ingår):

  ```powershell
  docker compose -f docker/dev/prom-grafana.yml up -d
  ```
* [ ] Öppna Grafana: `http://localhost:3000` (admin/admin → byt lösenord).
  **Förväntat:** Dashboards laddar; metrik uppdateras under körning.
  **Verifiera:** Paneler för throughput, error‑rate, latency.

---

## O) Testning (unit, integration, E2E, prestanda)

**Enkelt:** Alla tester gröna, inkl. E2E mot syntetiska sajter.

**Gör så här**

* [ ] Kör hela sviten:

  ```powershell
  make test
  ```
* [ ] Kör ett enskilt test:

  ```powershell
  pytest tests/test_crawler.py::test_pagination -q
  ```

**Förväntat:** `OK`/`passed`; rapport genereras under `htmlcov`/`reports`.
**Verifiera:** Täckningsgrad ≥ definierad tröskel (t.ex. 80%).

---

## P) Säkerhet & sekretess (RLS, nycklar, audit)

**Enkelt:** Lösen/nycklar skyddas; RLS och roller satta; audit‑loggar på plats.

**Gör så här**

* [ ] Kontrollera Supabase RLS‑policyer för tabeller med persondata.
* [ ] Rotera nycklar regelbundet; använd secrets manager i prod.
* [ ] Aktivera audit‑loggar (DB & app‑nivå).
  **Förväntat:** Endast behöriga kan läsa/skriva.
  **Verifiera:** Försök läsa med anon‑key när RLS kräver roll → nekas.

---

## Q) CI/CD (bygge, test, container, deploy)

**Enkelt:** Pipelines kör lint+test, bygger images, signerar SBOM, deployar till staging/prod.

**Gör så här**

* [ ] Push → GitHub Actions kör:

  * Lint/format (ruff, mypy, eslint, prettier)
  * Tester + täckning
  * Docker build & push (ghcr/ecr)
  * (Staging) Helm deploy
* [ ] Manuell release‑tag → prod deploy.
  **Förväntat:** Alla steg gröna innan merge.
  **Verifiera:** Actions‑logg, image i registry, poddar rullar i kluster.

---

## R) Infrastruktur (Docker Compose, Kubernetes/Helm)

**Enkelt:** Lokalt via Compose; staging/prod via K8s/Helm.

**Gör så här**

* [ ] Lokalt: `docker compose up -d api worker db redis`
* [ ] K8s: set values och:

  ```powershell
  helm upgrade --install crawler charts/crawler -n scraping
  ```

**Förväntat:** Pods `api`, `workers`, `proxy-pool` i `Running`.
**Verifiera:** `kubectl get pods -n scraping` → alla Ready.

---

## S) Funktionell färdigställan (UI & UX)

**Enkelt:** Alla sidor/resor fungerar: jobb, mallar, policyer, resultat, export, settings.

**Checklista**

* [ ] Routes definierade (home, jobs, templates, exports, settings, privacy)
* [ ] States stöds (normal/loading/empty/error/forbidden) via dev‑hooks
* [ ] Responsiv design (mobile/tablet/desktop)
* [ ] Dark mode (system/override)
* [ ] i18n (sv‑SE/en‑US, fallback)
* [ ] A11y: WCAG AA; Lighthouse a11y ≥ 90
* [ ] UI‑inventering exporterad (`ui-inventory.*`), `ui-catalog.md` genererad
  **Verifiera:** Manuell QA + Lighthouse rapporter sparade i `docs/qa/`.

---

## T) Datakvalitet & härkomst (DQ/Lineage)

**Enkelt:** Datavalidering, normalisering, PII‑skanning och lineage spårar varje datapost.

**Gör så här**

* [ ] Aktivera DQ‑regler per fält (regex, datumformat, landskod etc.).
* [ ] Normalisera (tidszon, telefonformat, registreringsnummer‑format).
* [ ] Spara lineage (käll‑URL, tid, mall‑version, selektor‑hash).
  **Förväntat:** Felaktiga rader flaggas, inte kraschar.
  **Verifiera:** `dq_metrics` uppdateras; rapport under `docs/analysis/`.

---

## U) Exportflöden & retention/erase

**Enkelt:** Exportjobben körs; retention‑policy och radering enligt GDPR.

**Gör så här**

* [ ] Sätt retention i `config/retention_policy.yml`.
* [ ] Kör `scripts/retention_job.py` via cron/scheduler.
* [ ] Implementera radering på begäran (erasure).
  **Förväntat:** Gamla artefakter arkiveras/raderas automatiskt.
  **Verifiera:** Loggar + minskad lagring i S3/GCS.

---

## V) Loggning & larm

**Enkelt:** Strukturerad JSON‑logg, korrelerad med job‑ID; larm vid 403/429‑spikar, hög felrate.

**Gör så här**

* [ ] Loggformat enligt `config/logging.yml`.
* [ ] Alert‑trösklar i Prometheus‑rules.
  **Förväntat:** Larm i Slack/e‑post vid incident.
  **Verifiera:** Testalarm genom att sänka tröskel i dev.

---

## W) Dokumentation & runbooks

**Enkelt:** Arkitektur, API, mall‑DSL, drift, felsökning och säkerhet dokumenterat.

**Gör så här**

* [ ] Uppdatera `docs/architecture.md`, `docs/api_documentation.md`, `docs/templates/dsl.md`.
* [ ] Lägg till runbooks: `403_storm.md`, `429_spike.md`, `proxy_drought.md`, `restore_drill.md`.
  **Förväntat:** Ny medlem kan komma igång på en dag.
  **Verifiera:** "Fresh pair of eyes" följer dokumenten utan att fastna.

---

## X) Kvalitetsgrindar (lint/format/typer)

**Enkelt:** Kodstilen enhetlig; typer kontrolleras.

**Gör så här**

* [ ] Python: ruff, mypy

  ```powershell
  ruff check .
  mypy src
  ```
* [ ] TS/JS: eslint, prettier

  ```powershell
  cd frontend
  npm run lint
  npm run format:check
  ```

**Förväntat:** Inga blockerande varningar.
**Verifiera:** CI passerar utan avsteg.

---

## Y) Prestanda & kapacitet

**Enkelt:** Systemet klarar definierade SLO (t.ex. X sidor/min, P95 < Y ms för API).

**Gör så här**

* [ ] Lasttesta API (k6/Locust).
* [ ] Mät throughput för crawler/scraper mot syntetiska sajter.
  **Förväntat:** Värden inom SLO.
  **Verifiera:** Rapporter i `docs/perf/`.

---

## Z) Release & versionshantering

**Enkelt:** Semver, CHANGELOG, taggar och immutabla artefakter.

**Gör så här**

* [ ] Bumpa version i `VERSION`; uppdatera `CHANGELOG.md`.
* [ ] Tagga:

  ```powershell
  git commit -am "release: v1.0.0"
  git tag v1.0.0
  git push && git push --tags
  ```

**Förväntat:** CI producerar artefakter för v1.0.0.
**Verifiera:** Image/tag i registry; release‑notes skapad.

---

## ÅÅ) Supportfunktioner & DX

**Enkelt:** Make‑mål, pre‑commit, devcontainers gör dev‑upplevelsen smidig.

**Gör så här**

* [ ] Aktivera pre‑commit:

  ```powershell
  pre-commit install
  ```
* [ ] Testa devcontainer (om definierad) i VS Code.
  **Förväntat:** Snabba feedbackloopar.
  **Verifiera:** Hookar kör lint/format vid commit.

---

## ÄÄ) Acceptanskriterier – sammanställning

**Färdig =** Alla nedan uppfyllda:

* [ ] Lokalt: `make docker-up`, `make run-api`, `npm run dev` fungerar samtidigt.
* [ ] DB migrations körda lokalt **och** i Supabase; RLS verifierad.
* [ ] REST/GraphQL‑API grönt i Postman/Insomnia; e2e‑flöden fungerar.
* [ ] Scraper/crawler extraherar data från samtliga tre syntetiska sajter; resultat i DB.
* [ ] Export till CSV/JSON **och** BigQuery fungerar.
* [ ] Observability visar realtidsmetrik; larm testade.
* [ ] UI responsivt, dark mode, i18n; Lighthouse a11y ≥ 90.
* [ ] Tester (unit/integration/E2E) gröna; täckning ≥ tröskel.
* [ ] CI/CD: automatiskt bygge/test/deploy till staging; manuell gated deploy till prod.
* [ ] Dokumentation och runbooks kompletta; onboarding < 1 dag.

---

## ÖÖ) Snabb felsökningsguide

* **Docker portar upptagna:** Ändra portar i `docker-compose.yml`; kör `docker ps` → stoppa konflikter.
* **Playwright fel:** Kör `python -m playwright install --with-deps` (macOS/Linux) eller uppdatera browsrar.
* **Frontend når inte API:** Kontrollera `VITE_API_URL` och CORS i backend.
* **RLS blockerar:** Testa med service‑role‑key i admin‑verktyg; korrigera policy.
* **403/429‑spikar:** Sänk RPS i `config/rate_limits.yml`; verifiera proxyhälsa.

---

> **Tips:** Spara ifylld checklista i repo (t.ex. `docs/release_checklists/release-1.0.md`) för spårbarhet. Lägg skärmdumpar på dashboards, API‑tests, och Lighthouse i `docs/qa/`.












Definition‑of‑Done” (DoD)



här kommer en “mega‑Definition‑of‑Done” (DoD) som är ~10× mer detaljerad. Jag skriver varje punkt så här: först en kort förklaring på enkel svenska (varför), sedan exakta kommandon/steg (hur), och till sist hur du verifierar (bevis). Jag utgår från din stack: Python 3.11+, FastAPI‑backend, Playwright‑/HTTP‑scraper, PostgreSQL lokalt i Docker med senare Supabase‑paritet, SSR‑frontend (Next.js rekommenderas) men med möjlighet att fortsätta köra befintlig React/Vite‑app tills migrationen är klar, Supabase Auth (lokalt/offline fallback), CI/CD via GitHub Actions, och full observability (Prometheus/Grafana/Otel).

Obs: där det står make … förutsätts att Makefile‑targets finns/läggs till (om de inte redan finns skapar vi dem i arbetet). Jag visar även PowerShell‑varianter där det är relevant på Windows.

1) Repo & grundhygien

Varför: En ren repo sparar tid och gör CI/CD stabil.
Gör så här:

Skapa/komplettera rotfiler: README.md, TREE.md, CHANGELOG.md, CONTRIBUTING.md, SECURITY.md, CODE_OF_CONDUCT.md, .editorconfig, .gitattributes, .gitignore, .dockerignore, Makefile, pyproject.toml, ruff.toml/mypy.ini, pytest.ini, pre-commit osv.

Aktivera pre‑commit hooks (lint/format/secret‑scan).

Kommandon:

# Installera pre-commit hooks
pip install pre-commit
pre-commit install

# Kör allt lokalt innan commit
pre-commit run --all-files


Verifiera:

pre-commit visar “Passed” per hook.

git status rent.

make fmt && make lint passerar utan fel.

2) Verktyg & versioner (låsa miljön)

Varför: Samma versioner överallt minskar “funkar bara på min dator”.
Gör så här:

Python 3.11+, Node LTS (18/20), pnpm/npm, Docker Desktop + Compose, Git.

Skapa .tool-versions (asdf) eller .nvmrc/.node-version.

Sätt upp uv/pip-tools för låsning av Python‑deps.

Kommandon:

python --version
node --version
npm --version
docker --version
docker compose version
git --version


Verifiera:

Versionerna matchar projektets dokumentation (skriv in i README).

pip-compile/uv pip compile genererar låsta requirements*.txt.

3) Hemligheter & konfig (12‑filsregeln)

Varför: Säkra, reproducerbara miljöer.
Gör så här:

Kopiera .env.example → .env.

Lägg hemligheter i OS‑nyckelring / 1Password / Doppler (inte i Git).

Lägg “env overlays”: config/env/development.yml, …/staging.yml, …/production.yml.

Kommandon:

# Windows PowerShell
Copy-Item .env.example .env
# macOS/Linux
cp .env.example .env


Verifiera:

make env-check läser in .env och validerar obligatoriska nycklar.

make config-validate validerar alla YAML med JSON‑schema.

4) Databas lokalt (Postgres i Docker) & Supabase‑paritet

Varför: Samma schema fungerar lokalt, i CI och i Supabase.
Gör så här:

Starta Postgres via Docker Compose.

Kör Alembic/SQL‑migrationer lokalt.

Spegla samma SQL i supabase/migrations/* så Supabase Studio kan applicera dem.

Kommandon:

docker compose -f docker/docker-compose.yml up -d db
make db-wait
make db-migrate   # Alembic/SQL
make db-seed


Verifiera:

psql → tabeller finns (ex: \dt visar jobs, results, templates …).

make db-health returnerar OK (kör SELECT 1).

Supabase (senare) visar identiskt schema under “Tables” och RLS‑policys aktiva.

5) Backend API (FastAPI) – hälsa, OpenAPI, GraphQL

Varför: Förutsägbart API med dokumentation.
Gör så här:

Implementera /healthz, /readyz, /metrics (Prometheus).

Aktivera OpenAPI på /docs och GraphQL (Strawberry/Ariadne) på /graphql.

Versionera API (/api/v1).

Kommandon:

make run-api
# eller
uvicorn src.webapp.app:app --reload --port 8080


Verifiera:

Öppna http://localhost:8080/healthz
 → {"status":"ok"}.

Öppna http://localhost:8080/docs
 (OpenAPI) och /graphql (playground).

curl http://localhost:8080/metrics → Prometheus‑metrics.

6) Autentisering – Supabase Auth + lokal fallback

Varför: Samma auth i dev/CI/prod, offline‑läge funkar ändå.
Gör så här:

Integrera Supabase Auth (JWT) i backend (bearer verifiering).

Lokal fallback: signerad “dev‑JWT” för E2E och offline‑demo.

Roller/claims mappas till RLS‑policys i DB.

Kommandon:

make run-api
# I .env: SUPABASE_JWT_SECRET=..., SUPABASE_PROJECT_URL=...


Verifiera:

Skyddade endpoints svarar 401 utan token och 200/403 med token beroende på roll.

make test-auth kör integrationstester för both “supabase” och “dev-jwt”.

7) Crawler – URL‑upptäckt, kö, policies

Varför: Stabil länk‑upptäckt utan loopar.
Gör så här:

Implementera BFS/DFS, djupbegränsning, domänfilter, duplicatkontroll (hash).

Domain‑policies (robots/ToS toggles, rate limits, honeypot‑filter).

Kö (Redis/DB) med idempotency‑nycklar och återupptagning.

Kommandon:

make run-crawler SEED_URL=https://example.com MAX_DEPTH=3


Verifiera:

jobs_crawler tabellen visar nya URL:er, inga duplicat.

Kör mot syntetiska testsajterna (se punkt 18) och kontrollera sitemap‑storlek.

8) Scraper – HTTP + Headless (Playwright) med stealth

Varför: Hantera både statiska och JS‑tunga sidor tillförlitligt.
Gör så här:

HTTP‑vägen: requests/httpx med kompletta headers, cookies, retry/backoff.

Browser‑vägen: Playwright (Chromium/Firefox/WebKit) med stealth‑patchar, resursblockering, timeouts, anti‑detection (navigator.webdriver, timezone, fonts).

Automatisk “diagnose → välj väg”: först HTTP, fallback till browser om 403/429/JS‑challenge.

Kommandon:

# Installera Playwright
python -m playwright install
# Starta en enkel scraping-körning
make run-scraper URL=https://example.com/page MODE=auto


Verifiera:

Loggar visar “http → ok” eller “http → blocked → browser → ok”.

Utdragna fält matchar selektorer i template (se punkt 9).

9) DSL för extraktion (mallar), validering & normalisering

Varför: Stabil, versionsbar extraktion som tål mindre layout‑drift.
Gör så här:

YAML‑DSL för fält (CSS/XPath, fallback‑listor, transformerare: trim, regex, date_parse).

Schemat valideras (pydantic) innan körning.

Normalisera (datum, tel, regnr/orgnr), och fält‑DQ (obligatoriskt, unikhet).

Kommandon:

make dsl-validate PATH=data/templates/vehicle_detail/template.yml
make scrape-with-template TEMPLATE=data/templates/vehicle_detail/template.yml URL=...


Verifiera:

make dsl-validate → “OK”.

Resultat JSON innehåller alla obligatoriska fält och passerar DQ‑regler.

10) Formflöden & interaktioner (inloggning, sök, pagination)

Varför: Data bakom interaktioner kräver “mänskliga” steg.
Gör så här:

“Flows” i DSL: fyll fält, klicka, vänta på selector/XHR, infinite scroll med sentinel.

Inloggning: separat modul (secrets via vault/.env), session‑persistens (krypterad).

Honeypot‑detektering (ignorera osynliga fält).

Kommandon:

make run-flow FLOW=data/templates/form_flow/example.yml


Verifiera:

Video/tracing från Playwright (artefakt) visar korrekta steg.

Sökresultat exekveras och extraheras konsekvent i E2E‑testerna.

11) Proxy‑pool, IP‑rotation & kvalitet

Varför: Minska blockeringar (429/403), efterlikna riktiga användare.
Gör så här:

Proxy‑katalog (residential/datacenter/sticky), liveness‑check, kvalitets‑score.

Per‑domän policy: sticky vs per‑request rotation, region/language matchning.

API för att hämta/nollställa/rapportera proxy‑hälsa.

Kommandon:

make proxypool-up
make proxypool-validate


Verifiera:

Dashboard “Proxy Health” i Grafana (se punkt 20) visar p50/p95 latens, fail‑rate.

Scraping‑körning visar sjunkande 403/429 jämfört med kontroll.

12) Hastighet, backoff & “circuit breakers”

Varför: Botas om man hamrar för hårt.
Gör så här:

Per‑domän RPS‑limits, jitter (slump), politeness delay, time‑windows.

Exponentiell backoff för transienta fel.

Circuit breaker: pausar domän vid felspikar (429/403 > tröskel).

Kommandon:

make rate-limit-test DOMAIN=example.com RPS=2


Verifiera:

Loggar visar “breaker OPEN/CLOSED” och att köer pausas/återupptas korrekt.

Prometheus‑metrics för crawl_rps, error_rate följer inställningar.

13) Data‑modell & migrationer (paritet lokalt/Supabase)

Varför: Förutsägbar datalagring, enkel uppgradering/rollback.
Gör så här:

Tabeller: jobs, urls, pages_raw, extractions, entities, lineage, dq_metrics, audit.

Indexer (URL‑hash, job_id, updated_at), FK med ON DELETE.

RLS‑policys enligt roller (viewer/editor/admin/service).

Kommandon:

make db-revision msg="add dq tables"
make db-migrate


Verifiera:

SELECT på systemtabellerna visar nya revisioner.

Supabase kör samma SQL i “SQL Editor” och Studio visar identiskt.

14) Integritetscenter: Radering, retention, persondata

Varför: Undvik risk, kunna radera på begäran.
Gör så här:

Tabell “erasure_requests” + arbetare som “tombstonar” och raderar.

Retention‑jobb som plockar gamla rådata (S3/bucket lifecycle).

PII‑scanner (regex/ML) och flaggar datafält.

Kommandon:

make privacy-erasure-test ENTITY_ID=...
make retention-dry-run DAYS=90


Verifiera:

Raderade rader syns inte längre i queries; audit log visar “erased_by job_id…”.

Retention‑rapport exporteras (CSV) och bifogas Slack/Email.

15) Exporter & connectors (CSV/JSON/Excel/Sheets/BigQuery/ES)

Varför: Data ut ur systemet dit du vill.
Gör så här:

Exporter är pluggbar: välj --target csv|json|excel|sheets|bigquery|opensearch.

Konfigureras via config/export_targets.yml.

Idempotens & resume (checkpoint).

Kommandon:

make export TARGET=csv QUERY="select * from extractions limit 100" OUT=data/exports/export.csv
make export TARGET=bigquery DATASET=my_ds TABLE=extractions


Verifiera:

Fil skapad med rätt antal rader.

BigQuery‑tabellen uppdaterad; “job finished” i logg.

16) Frontend – strategi (befintlig Vite‑app → SSR Next.js)

Varför: Bäst UX/SEO, auth på serversidan, snabb initial rendering.
Gör så här:

Fortsätt köra befintlig frontend/ (Vite/React) under utveckling.

Planera migrering till Next.js (App Router) med Supabase Auth (SSR).

UI måste ha: responsive breakpoints, dark mode, i18n (sv/en), states (normal/loading/empty/error/forbidden).

Kommandon (befintlig):

cd frontend
npm ci
npm run dev


Kommandon (ny SSR-app parallellt):

npx create-next-app@latest web --ts --eslint --tailwind
cd web
npm i @supabase/auth-helpers-nextjs @supabase/supabase-js @tanstack/react-query zod


Verifiera:

Vite: http://localhost:5173
 svarar.

Next.js: http://localhost:3000
 svarar.

Inloggning funkar server‑side (skyddade rutter återrenderar på servern).

17) Frontend – routes, state‑hooks, breakpoints, dark mode, i18n

Varför: Konsekvent UX.
Gör så här:

Routes‑lista (jobs, templates, runs, data, proxies, privacy, settings).

States via dev‑hooks (normal/loading/empty/error/forbidden) och storybook/preview.

Breakpoints Tailwind/TanStack layout, mobilt först.

Dark mode via Tailwind class + system‑pref.

i18n: lingui/next‑intl med locale‑filer sv-SE/en-US.

Kommandon:

# Generera “UI‑inventering” (DOM snapshot, statisk inventering, katalog)
npm run ui:inventory   # script som kör Playwright + DOM‑Exporter
# Lighthouse a11y
npm run audit:a11y


Verifiera:

Filer skapade i repo:

ui-inventory.dom.json + .csv

ui-inventory.static.json

ui-catalog.md

Lighthouse rapport visar ≥ 90 i Accessibility.

18) Syntetiska testsajter (E2E‑sandlåda)

Varför: Testa allt lokalt utan att slå externa sajter.
Gör så här:

Docker Compose som startar 3 sajter: statisk lista (pagination), infinite scroll, form‑flow.

E2E‑tester (Playwright) kör mot dessa.

Kommandon:

make docker-up-synthetic
# Kolla de tre sajterna
# http://localhost:8081, :8082, :8083 (exempel)
make docker-down-synthetic


Verifiera:

Alla tre svarar i webbläsaren.

npm run e2e (eller make e2e) passerar.

19) Tester – enhet, integration, E2E, property, mutation, fuzz

Varför: Kvalitet & regressionsskydd.
Gör så här:

Unit: selektorer, transformers, validators.

Integration: http scraper, browser scraper, scheduler, exports.

E2E: hela flöden mot syntetiska sajter.

Property‑based (Hypothesis) för selektorer/transformers.

Mutation‑testing (mutmut) på kritiska moduler.

Fuzz (AFL‑liknande) för HTML‑parser.

Performance (k6) & Chaos (döda worker, proxy‑degradering).

Kommandon:

make test       # allt
make test-unit
make test-integration
make test-e2e
make test-mutation
make test-fuzz
make perf-k6
make chaos


Verifiera:

Alla pipelines gröna, mutation score över tröskel (t.ex. ≥ 70%).

k6 visar P95 < definierad SLA.

20) Observability – loggar, metrics, tracing (Prometheus/Grafana/Otel)

Varför: Se vad som händer och reagera innan kunder märker.
Gör så här:

Strukturerade JSON‑loggar (correlation IDs).

Prometheus metrics från API, workers, proxy‑pool.

OpenTelemetry traces (OTLP till Tempo/Jaeger).

Grafana dashboards: scraping_overview, proxy_health, queues, db_dq, cost.

Kommandon:

docker compose -f monitoring/docker-compose.obsv.yml up -d
# API exponerar /metrics, Otel Collector tar emot traces


Verifiera:

Grafana uppe (t.ex. http://localhost:3001
).

Dashboards visar trafik, fel, latens, ban‑rate.

Larm (Alertmanager) triggar på trösklar (testa “smoke alert”).

21) Säkerhet – SAST, dep‑scan, container‑scan, SBOM, signing

Varför: Minska risk (sårbarheter, supply‑chain).
Gör så här:

SAST (Bandit, ruff‑rules), Dependabot/OSV‑scan, Trivy för images.

Skapa SBOM (Syft), signera images (Cosign), policy (Rekor/verify).

Secret‑scan (gitleaks/trufflehog) i pre‑commit och CI.

Kommandon:

make sast
make dep-scan
make image-scan
make sbom
make cosign-sign
make cosign-verify
``]
**Verifiera:**  
- CI artifacts innehåller rapporter; inga “High/Critical” kvar vid merge.  
- Cosign verify OK på publika images i registry.

---

# 22) CI/CD – GitHub Actions (build, test, sbom, release, deploy)

**Varför:** Automatisk kvalitet och snabb leverans.  
**Gör så här:**  
- Pipelines:  
  1) Lint/Type → 2) Unit → 3) Integration → 4) E2E → 5) Security → 6) SBOM/Sign → 7) Build & Push → 8) Deploy Staging → 9) Canary Prod → 10) Release notes.  
- Caching (pip/pnpm/Playwright), parallell matris (py 3.11/3.12, os).  
- Miljöhemligheter via GitHub Environments.

**Kommandon:**
```bash
# Lokalt “rökprov” innan push
make ci-local


Verifiera:

Alla workflows gröna.

Release skapad med changelog, image taggad app:vX.Y.Z.

23) API‑klienter & SDK (Python/TS), Postman/Insomnia

Varför: Snabb integration för konsumenter.
Gör så här:

Generera SDK från OpenAPI (/docs/openapi.yaml).

Publicera paket (privat registry eller GH Packages).

Postman/Insomnia export + exempel.

Kommandon:

make gen-openapi-clients
make sdk-publish


Verifiera:

pip install scraping-sdk==X.Y.Z fungerar; enkel kodsnutt hämtar data.

Postman‑samling kör tre scenarion utan fel.

24) Dokumentation komplett

Varför: Lätt att förstå, lätt att underhålla.
Gör så här:

Arkitektur, systemdesignbeslut (ADR), dev‑guide, usage‑guide, database schema, API‑docs, observability, security, runbooks (403 storm, 429 spike, proxy drought, restore drill), policies (robots/ToS toggle, GDPR/DPIA mallar).

UI‑katalog (ui-catalog.md), DSL‑manual med exempel.

Kommandon:

make docs-validate  # länk-kontroll, schema-koll, ADR-index


Verifiera:

Docs bygger (MkDocs/Docusaurus) och länkar fungerar.

Alla runbooks har “last reviewed” datum.

25) Produktion – Kubernetes/GCP (eller valfritt moln) + Supabase

Varför: Skalbar, robust drift.
Gör så här:

K8s manifester: namespace, configmaps, secrets (via External Secrets), deployments (api/workers/proxy‑pool), services, ingress, HPA, PDB, CronJobs (backup, retention, erasure, sbom, cost report).

Artifact registry (GCR/AR), Cloud Load Balancer/Ingress, Managed Prometheus/Grafana, GCS buckets (raw/html, exports, backups).

Supabase instans kopplad (eller egen Postgres på Cloud SQL med paritet).

Kommandon (exempel):

kubectl apply -k iac/k8s/
# eller Helm:
helm upgrade --install crawler ./docker/k8s/helm -f docker/k8s/helm/values.yaml


Verifiera:

kubectl get pods alla Running/Ready.

Ingress svarar 200, metrics skrapas, autoscaling triggar under last.

26) Kost & hushållning

Varför: Undvik överraskningar, rensa gammalt.
Gör så här:

Budget‑alerts, dashboards för kost (per komponent).

Lifecycle regler för buckets.

Städuppgifter (cron) för temp‑artefakter, gamla sessioner, misslyckade jobb.

Kommandon:

make cost-report
make gc


Verifiera:

Grafana “Cost Overview” uppdateras.

Buckets visar förväntat antal objekt efter lifecycle‑körning.

27) Backup, DR & övningar

Varför: När det brinner ska återställning sitta i ryggraden.
Gör så här:

Dagliga DB‑backuper (WAL‑G/pgBackRest) → GCS/S3 med retention.

Restore drill kvartalsvis (isolerad miljö), kontrollera checksums/integritet.

Export av kritiska configs (dashboards, alerts, policies).

Kommandon:

make backup-now
make restore-drill


Verifiera:

Återställningstid (RTO) & förlorad data (RPO) uppfyller mål.

Checklista signerad efter varje drill.

28) Efterlevnad & etiska kontroller (togglar + default‑safe)

Varför: Minimera juridisk risk och var “artigt” som standard.
Gör så här:

“Policy Toggle” i UI: robots/ToS‑respekt, rate‑limit‑nivåer, data‑minimering.

DPIA‑mall ifylld för typiska datakällor; privacy center dokumenterat.

Audit log av policy‑ändringar.

Kommandon:

make policy-check


Verifiera:

Policy‑ändringar loggas, export av audit log körbar.

29) Release‑process & semver

Varför: Förutsägbar leverans.
Gör så här:

Conventional commits → auto‑changelog.

Semver taggning, release‑notes pipeline, canary → prod promotion.

Feature flags för riskabla delar.

Kommandon:

make release TYPE=minor


Verifiera:

Ny tag och GitHub Release med länkat changelog.

Canary‑trafik visar noll/acceptabel felgrad före full rollout.

30) Operativ drift – daglig checklista

Varför: Mindre brandkårsutryckningar.
Gör så här:

Daglig hälsorapport (graf, felkvot, proxyhälsa, ködjup, kost).

Pager‑regler vid larm med tydliga “first actions”.

Veckovis städning och “selector regression suite” nattlig.

Kommandon:

make daily-report
make nightly-selector-regression


Verifiera:

Rapport skickas till Slack/email; regression‑suite rapporterar “0 drift”.

Extra: detaljerade “klar‑kriterier” per modul (kortfattat)

Crawler: inga duplicat, inga loopar, rätt djup, sitemap densitet över tröskel, policy per domän aktiv.

Scraper: auto‑diagnose väljer HTTP→browser korrekt, P95 render‑tid < SLA, resursblockering sparar ≥30% bandbredd.

Templates/DSL: validering sträng, fallback‑selektorer funkar, transformationsbibliotek täcker 95% fält.

Proxy‑pool: hälsoscore uppdateras; ban‑rate < definierad mål (t.ex. <2%).

Scheduler: jobb kan pausas/återupptas; poison queue isolerar “värstingar”.

DB/RLS: alla SELECT/INSERT respekterar roll; erasure/retention loggade.

Exports: stora dataset fungerar (chunking, idempotens).

Frontend: alla rutter listade; alla UI‑states demonstrerade; mobil/tablet/desktop pixel‑perf; dark mode class‑toggle OK; i18n 100% täckning.

Observability: dashboards färdiga; alert‑regler med runbooks; spårbarhet med correlation‑IDs.

Security: SAST/deps/container scan gröna; SBOM skapad & signerad; secrets aldrig i Git.

CI/CD: alla jobb gröna; artifacts bevarade; rollback via Helm/Argo kubectl fungerar.

Prod/K8s: HPA skalar upp/ner på last; PDB hindrar total nertid; CronJobs körs och loggas.

Docs: ADRs för större beslut; API‑docs uppdaterade; “first hour” guide för nya devs.

DR: bevisad restore‑drill inom mål‑RTO/RPO.

Operations: daily/weekly körs; månadens rapport signeras.

Snabb körordning (om du vill “bocka av” från noll)

Miljö & verktyg (pkt 2–3) → pre-commit, .env, config/*.

DB lokalt (pkt 4 & 13) → docker up db, make db-migrate, db-seed.

Backend (pkt 5–6) → make run-api, OpenAPI/GraphQL, auth‑checks.

Syntetiska sajter (pkt 18) → make docker-up-synthetic.

Crawler/Scraper (pkt 7–12) → första end‑to‑end‑körning, templates.

Observability (pkt 20) → Prometheus/Grafana/Otel upp; dashboards.

Tester (pkt 19) → allt grönt inkl. E2E.

Frontend (pkt 16–17) → kör Vite nu; kör Next.js POC parallellt.

Exports/Privacy (pkt 14–15) → retention/erasure & exporters.

Security & CI/CD (pkt 21–22) → pipelines, sbom/sign.

Docs & SDK (pkt 23–24).

Prod/K8s/GCP (pkt 25–27) → staging → canary → prod.

Operations (pkt 28–30).







