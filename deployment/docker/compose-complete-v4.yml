# Revolutionary Ultimate System v4.0 - Complete Docker Stack
# Production-ready containerized services for all integrated components

version: '3.8'

services:
  # ===== MAIN APPLICATION =====
  revolutionary-scraper:
    build:
      context: .
      dockerfile: docker/Dockerfile.revolutionary-v4
    container_name: revolutionary-scraper
    ports:
      - "8000:8000"  # Main API
      - "8001:8001"  # Prometheus metrics
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - DATABASE_URL=postgresql://scraper:scraper_password@postgres:5432/scraper_db
      - REDIS_URL=redis://redis:6379/0
      - FLARESOLVERR_URL=http://flaresolverr:8191
      - TIKA_URL=http://tika:9998
      - BROWSERLESS_URL=ws://browserless:3000
    depends_on:
      - postgres
      - redis
      - flaresolverr
      - tika
    volumes:
      - ./config:/app/config:ro
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===== ANTI-BOT SERVICES =====
  # FlareSolverr for CloudFlare bypass
  flaresolverr:
    image: flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    ports:
      - "8191:8191"
    environment:
      - LOG_LEVEL=info
      - CAPTCHA_SOLVER=none
      - TZ=UTC
    volumes:
      - flaresolverr-sessions:/app/sessions
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8191/v1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Browserless for headless Chrome pool
  browserless:
    image: browserless/chrome:latest
    container_name: browserless
    ports:
      - "3000:3000"
    environment:
      - MAX_CONCURRENT_SESSIONS=10
      - CONNECTION_TIMEOUT=60000
      - CHROME_REFRESH_TIME=2000
      - DEFAULT_BLOCK_ADS=true
      - ENABLE_CORS=true
      - WORKSPACE_DELETE_EXPIRED=true
      - METRICS_JSON_PATH=/workspace/metrics.json
    volumes:
      - browserless-workspace:/workspace
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/json/version"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===== CONTENT EXTRACTION SERVICES =====
  # Apache Tika for document processing
  tika:
    image: apache/tika:latest
    container_name: tika
    ports:
      - "9998:9998"
    environment:
      - TIKA_CONFIG=/opt/tika-config.xml
    volumes:
      - ./docker/tika-config.xml:/opt/tika-config.xml:ro
      - tika-temp:/tmp
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9998/tika"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Tesseract OCR service (optional)
  tesseract-ocr:
    build:
      context: ./docker
      dockerfile: Dockerfile.tesseract
    container_name: tesseract-ocr
    ports:
      - "5000:5000"
    environment:
      - TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata
      - OMP_THREAD_LIMIT=1
    volumes:
      - tesseract-data:/app/uploads
    networks:
      - revolutionary-network
    restart: unless-stopped

  # ===== DATABASE SERVICES =====
  # PostgreSQL for data storage
  postgres:
    image: postgres:15-alpine
    container_name: revolutionary-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=scraper_db
      - POSTGRES_USER=scraper
      - POSTGRES_PASSWORD=scraper_password
      - POSTGRES_INITDB_ARGS=--locale=sv_SE.UTF-8
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./docker/postgres-init:/docker-entrypoint-initdb.d:ro
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scraper -d scraper_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and task queues
  redis:
    image: redis:7-alpine
    container_name: revolutionary-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass redis_password
    volumes:
      - redis-data:/data
      - ./docker/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===== MONITORING SERVICES =====
  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: revolutionary-prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: revolutionary-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin_password
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===== PROXY SERVICES =====
  # Squid proxy for testing and rotation
  squid-proxy:
    image: ubuntu/squid:latest
    container_name: revolutionary-squid
    ports:
      - "3128:3128"
    volumes:
      - ./docker/squid.conf:/etc/squid/squid.conf:ro
    networks:
      - revolutionary-network
    restart: unless-stopped

  # HAProxy for load balancing and proxy rotation
  haproxy:
    image: haproxy:2.8-alpine
    container_name: revolutionary-haproxy
    ports:
      - "8080:8080"  # Load balancer
      - "8404:8404"  # Stats page
    volumes:
      - ./docker/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    networks:
      - revolutionary-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===== QUEUE & TASK PROCESSING =====
  # Celery worker for background tasks
  celery-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.revolutionary-v4
    container_name: revolutionary-celery
    command: celery -A revolutionary_scraper.celery worker --loglevel=info --concurrency=4
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - DATABASE_URL=postgresql://scraper:scraper_password@postgres:5432/scraper_db
    depends_on:
      - postgres
      - redis
    volumes:
      - ./config:/app/config:ro
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - revolutionary-network
    restart: unless-stopped

  # Celery beat for scheduled tasks
  celery-beat:
    build:
      context: .
      dockerfile: docker/Dockerfile.revolutionary-v4
    container_name: revolutionary-celery-beat
    command: celery -A revolutionary_scraper.celery beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - DATABASE_URL=postgresql://scraper:scraper_password@postgres:5432/scraper_db
    depends_on:
      - postgres
      - redis
    volumes:
      - ./config:/app/config:ro
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - revolutionary-network
    restart: unless-stopped

  # ===== DEVELOPMENT SERVICES =====
  # Jupyter for data analysis and development
  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: revolutionary-jupyter
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=jupyter_token
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data:ro
    networks:
      - revolutionary-network
    restart: unless-stopped
    profiles:
      - development

  # MinIO for S3-compatible object storage
  minio:
    image: minio/minio:latest
    container_name: revolutionary-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=admin_password
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - revolutionary-network
    restart: unless-stopped
    profiles:
      - development
      - production

  # ===== SECURITY SERVICES =====
  # Fail2ban for security
  fail2ban:
    build:
      context: ./docker
      dockerfile: Dockerfile.fail2ban
    container_name: revolutionary-fail2ban
    privileged: true
    environment:
      - F2B_LOG_LEVEL=INFO
      - F2B_IPTABLES_CHAIN=INPUT
    volumes:
      - ./logs:/var/log/scraper:ro
      - ./docker/fail2ban/jail.conf:/etc/fail2ban/jail.local:ro
      - /var/lib/fail2ban:/var/lib/fail2ban
    networks:
      - revolutionary-network
    restart: unless-stopped
    profiles:
      - production

  # ===== UTILITY SERVICES =====
  # Watchtower for automatic updates
  watchtower:
    image: containrrr/watchtower:latest
    container_name: revolutionary-watchtower
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_POLL_INTERVAL=3600
      - WATCHTOWER_INCLUDE_STOPPED=false
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - revolutionary-network
    restart: unless-stopped
    profiles:
      - production

  # Portainer for container management
  portainer:
    image: portainer/portainer-ce:latest
    container_name: revolutionary-portainer
    ports:
      - "9443:9443"
    command: -H unix:///var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer-data:/data
    networks:
      - revolutionary-network
    restart: unless-stopped
    profiles:
      - development

  # ===== BACKUP SERVICES =====
  # Automated backup service
  backup:
    build:
      context: ./docker
      dockerfile: Dockerfile.backup
    container_name: revolutionary-backup
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=scraper_db
      - POSTGRES_USER=scraper
      - POSTGRES_PASSWORD=scraper_password
      - BACKUP_SCHEDULE="0 2 * * *"  # Daily at 2 AM
      - BACKUP_RETENTION_DAYS=30
      - S3_ENDPOINT=http://minio:9000
      - S3_ACCESS_KEY=admin
      - S3_SECRET_KEY=admin_password
      - S3_BUCKET=backups
    depends_on:
      - postgres
      - minio
    volumes:
      - ./backups:/backups
      - backup-temp:/tmp
    networks:
      - revolutionary-network
    restart: unless-stopped
    profiles:
      - production

# ===== NETWORKS =====
networks:
  revolutionary-network:
    driver: bridge
    name: revolutionary-network
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16

# ===== VOLUMES =====
volumes:
  # Database volumes
  postgres-data:
    driver: local
  redis-data:
    driver: local
    
  # Application volumes
  flaresolverr-sessions:
    driver: local
  browserless-workspace:
    driver: local
  tika-temp:
    driver: local
  tesseract-data:
    driver: local
    
  # Monitoring volumes
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
    
  # Storage volumes
  minio-data:
    driver: local
  backup-temp:
    driver: local
    
  # Development volumes
  portainer-data:
    driver: local

# ===== PROFILES =====
# Use profiles to control which services run:
# docker-compose --profile development up  (includes dev tools)
# docker-compose --profile production up   (includes security/backup)
# docker-compose up                         (core services only)
