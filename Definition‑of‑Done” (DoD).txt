Definition‑of‑Done” (DoD)



här kommer en “mega‑Definition‑of‑Done” (DoD) som är ~10× mer detaljerad. Jag skriver varje punkt så här: först en kort förklaring på enkel svenska (varför), sedan exakta kommandon/steg (hur), och till sist hur du verifierar (bevis). Jag utgår från din stack: Python 3.11+, FastAPI‑backend, Playwright‑/HTTP‑scraper, PostgreSQL lokalt i Docker med senare Supabase‑paritet, SSR‑frontend (Next.js rekommenderas) men med möjlighet att fortsätta köra befintlig React/Vite‑app tills migrationen är klar, Supabase Auth (lokalt/offline fallback), CI/CD via GitHub Actions, och full observability (Prometheus/Grafana/Otel).

Obs: där det står make … förutsätts att Makefile‑targets finns/läggs till (om de inte redan finns skapar vi dem i arbetet). Jag visar även PowerShell‑varianter där det är relevant på Windows.

1) Repo & grundhygien

Varför: En ren repo sparar tid och gör CI/CD stabil.
Gör så här:

Skapa/komplettera rotfiler: README.md, TREE.md, CHANGELOG.md, CONTRIBUTING.md, SECURITY.md, CODE_OF_CONDUCT.md, .editorconfig, .gitattributes, .gitignore, .dockerignore, Makefile, pyproject.toml, ruff.toml/mypy.ini, pytest.ini, pre-commit osv.

Aktivera pre‑commit hooks (lint/format/secret‑scan).

Kommandon:

# Installera pre-commit hooks
pip install pre-commit
pre-commit install

# Kör allt lokalt innan commit
pre-commit run --all-files


Verifiera:

pre-commit visar “Passed” per hook.

git status rent.

make fmt && make lint passerar utan fel.

2) Verktyg & versioner (låsa miljön)

Varför: Samma versioner överallt minskar “funkar bara på min dator”.
Gör så här:

Python 3.11+, Node LTS (18/20), pnpm/npm, Docker Desktop + Compose, Git.

Skapa .tool-versions (asdf) eller .nvmrc/.node-version.

Sätt upp uv/pip-tools för låsning av Python‑deps.

Kommandon:

python --version
node --version
npm --version
docker --version
docker compose version
git --version


Verifiera:

Versionerna matchar projektets dokumentation (skriv in i README).

pip-compile/uv pip compile genererar låsta requirements*.txt.

3) Hemligheter & konfig (12‑filsregeln)

Varför: Säkra, reproducerbara miljöer.
Gör så här:

Kopiera .env.example → .env.

Lägg hemligheter i OS‑nyckelring / 1Password / Doppler (inte i Git).

Lägg “env overlays”: config/env/development.yml, …/staging.yml, …/production.yml.

Kommandon:

# Windows PowerShell
Copy-Item .env.example .env
# macOS/Linux
cp .env.example .env


Verifiera:

make env-check läser in .env och validerar obligatoriska nycklar.

make config-validate validerar alla YAML med JSON‑schema.

4) Databas lokalt (Postgres i Docker) & Supabase‑paritet

Varför: Samma schema fungerar lokalt, i CI och i Supabase.
Gör så här:

Starta Postgres via Docker Compose.

Kör Alembic/SQL‑migrationer lokalt.

Spegla samma SQL i supabase/migrations/* så Supabase Studio kan applicera dem.

Kommandon:

docker compose -f docker/docker-compose.yml up -d db
make db-wait
make db-migrate   # Alembic/SQL
make db-seed


Verifiera:

psql → tabeller finns (ex: \dt visar jobs, results, templates …).

make db-health returnerar OK (kör SELECT 1).

Supabase (senare) visar identiskt schema under “Tables” och RLS‑policys aktiva.

5) Backend API (FastAPI) – hälsa, OpenAPI, GraphQL

Varför: Förutsägbart API med dokumentation.
Gör så här:

Implementera /healthz, /readyz, /metrics (Prometheus).

Aktivera OpenAPI på /docs och GraphQL (Strawberry/Ariadne) på /graphql.

Versionera API (/api/v1).

Kommandon:

make run-api
# eller
uvicorn src.webapp.app:app --reload --port 8080


Verifiera:

Öppna http://localhost:8080/healthz
 → {"status":"ok"}.

Öppna http://localhost:8080/docs
 (OpenAPI) och /graphql (playground).

curl http://localhost:8080/metrics → Prometheus‑metrics.

6) Autentisering – Supabase Auth + lokal fallback

Varför: Samma auth i dev/CI/prod, offline‑läge funkar ändå.
Gör så här:

Integrera Supabase Auth (JWT) i backend (bearer verifiering).

Lokal fallback: signerad “dev‑JWT” för E2E och offline‑demo.

Roller/claims mappas till RLS‑policys i DB.

Kommandon:

make run-api
# I .env: SUPABASE_JWT_SECRET=..., SUPABASE_PROJECT_URL=...


Verifiera:

Skyddade endpoints svarar 401 utan token och 200/403 med token beroende på roll.

make test-auth kör integrationstester för both “supabase” och “dev-jwt”.

7) Crawler – URL‑upptäckt, kö, policies

Varför: Stabil länk‑upptäckt utan loopar.
Gör så här:

Implementera BFS/DFS, djupbegränsning, domänfilter, duplicatkontroll (hash).

Domain‑policies (robots/ToS toggles, rate limits, honeypot‑filter).

Kö (Redis/DB) med idempotency‑nycklar och återupptagning.

Kommandon:

make run-crawler SEED_URL=https://example.com MAX_DEPTH=3


Verifiera:

jobs_crawler tabellen visar nya URL:er, inga duplicat.

Kör mot syntetiska testsajterna (se punkt 18) och kontrollera sitemap‑storlek.

8) Scraper – HTTP + Headless (Playwright) med stealth

Varför: Hantera både statiska och JS‑tunga sidor tillförlitligt.
Gör så här:

HTTP‑vägen: requests/httpx med kompletta headers, cookies, retry/backoff.

Browser‑vägen: Playwright (Chromium/Firefox/WebKit) med stealth‑patchar, resursblockering, timeouts, anti‑detection (navigator.webdriver, timezone, fonts).

Automatisk “diagnose → välj väg”: först HTTP, fallback till browser om 403/429/JS‑challenge.

Kommandon:

# Installera Playwright
python -m playwright install
# Starta en enkel scraping-körning
make run-scraper URL=https://example.com/page MODE=auto


Verifiera:

Loggar visar “http → ok” eller “http → blocked → browser → ok”.

Utdragna fält matchar selektorer i template (se punkt 9).

9) DSL för extraktion (mallar), validering & normalisering

Varför: Stabil, versionsbar extraktion som tål mindre layout‑drift.
Gör så här:

YAML‑DSL för fält (CSS/XPath, fallback‑listor, transformerare: trim, regex, date_parse).

Schemat valideras (pydantic) innan körning.

Normalisera (datum, tel, regnr/orgnr), och fält‑DQ (obligatoriskt, unikhet).

Kommandon:

make dsl-validate PATH=data/templates/vehicle_detail/template.yml
make scrape-with-template TEMPLATE=data/templates/vehicle_detail/template.yml URL=...


Verifiera:

make dsl-validate → “OK”.

Resultat JSON innehåller alla obligatoriska fält och passerar DQ‑regler.

10) Formflöden & interaktioner (inloggning, sök, pagination)

Varför: Data bakom interaktioner kräver “mänskliga” steg.
Gör så här:

“Flows” i DSL: fyll fält, klicka, vänta på selector/XHR, infinite scroll med sentinel.

Inloggning: separat modul (secrets via vault/.env), session‑persistens (krypterad).

Honeypot‑detektering (ignorera osynliga fält).

Kommandon:

make run-flow FLOW=data/templates/form_flow/example.yml


Verifiera:

Video/tracing från Playwright (artefakt) visar korrekta steg.

Sökresultat exekveras och extraheras konsekvent i E2E‑testerna.

11) Proxy‑pool, IP‑rotation & kvalitet

Varför: Minska blockeringar (429/403), efterlikna riktiga användare.
Gör så här:

Proxy‑katalog (residential/datacenter/sticky), liveness‑check, kvalitets‑score.

Per‑domän policy: sticky vs per‑request rotation, region/language matchning.

API för att hämta/nollställa/rapportera proxy‑hälsa.

Kommandon:

make proxypool-up
make proxypool-validate


Verifiera:

Dashboard “Proxy Health” i Grafana (se punkt 20) visar p50/p95 latens, fail‑rate.

Scraping‑körning visar sjunkande 403/429 jämfört med kontroll.

12) Hastighet, backoff & “circuit breakers”

Varför: Botas om man hamrar för hårt.
Gör så här:

Per‑domän RPS‑limits, jitter (slump), politeness delay, time‑windows.

Exponentiell backoff för transienta fel.

Circuit breaker: pausar domän vid felspikar (429/403 > tröskel).

Kommandon:

make rate-limit-test DOMAIN=example.com RPS=2


Verifiera:

Loggar visar “breaker OPEN/CLOSED” och att köer pausas/återupptas korrekt.

Prometheus‑metrics för crawl_rps, error_rate följer inställningar.

13) Data‑modell & migrationer (paritet lokalt/Supabase)

Varför: Förutsägbar datalagring, enkel uppgradering/rollback.
Gör så här:

Tabeller: jobs, urls, pages_raw, extractions, entities, lineage, dq_metrics, audit.

Indexer (URL‑hash, job_id, updated_at), FK med ON DELETE.

RLS‑policys enligt roller (viewer/editor/admin/service).

Kommandon:

make db-revision msg="add dq tables"
make db-migrate


Verifiera:

SELECT på systemtabellerna visar nya revisioner.

Supabase kör samma SQL i “SQL Editor” och Studio visar identiskt.

14) Integritetscenter: Radering, retention, persondata

Varför: Undvik risk, kunna radera på begäran.
Gör så här:

Tabell “erasure_requests” + arbetare som “tombstonar” och raderar.

Retention‑jobb som plockar gamla rådata (S3/bucket lifecycle).

PII‑scanner (regex/ML) och flaggar datafält.

Kommandon:

make privacy-erasure-test ENTITY_ID=...
make retention-dry-run DAYS=90


Verifiera:

Raderade rader syns inte längre i queries; audit log visar “erased_by job_id…”.

Retention‑rapport exporteras (CSV) och bifogas Slack/Email.

15) Exporter & connectors (CSV/JSON/Excel/Sheets/BigQuery/ES)

Varför: Data ut ur systemet dit du vill.
Gör så här:

Exporter är pluggbar: välj --target csv|json|excel|sheets|bigquery|opensearch.

Konfigureras via config/export_targets.yml.

Idempotens & resume (checkpoint).

Kommandon:

make export TARGET=csv QUERY="select * from extractions limit 100" OUT=data/exports/export.csv
make export TARGET=bigquery DATASET=my_ds TABLE=extractions


Verifiera:

Fil skapad med rätt antal rader.

BigQuery‑tabellen uppdaterad; “job finished” i logg.

16) Frontend – strategi (befintlig Vite‑app → SSR Next.js)

Varför: Bäst UX/SEO, auth på serversidan, snabb initial rendering.
Gör så här:

Fortsätt köra befintlig frontend/ (Vite/React) under utveckling.

Planera migrering till Next.js (App Router) med Supabase Auth (SSR).

UI måste ha: responsive breakpoints, dark mode, i18n (sv/en), states (normal/loading/empty/error/forbidden).

Kommandon (befintlig):

cd frontend
npm ci
npm run dev


Kommandon (ny SSR-app parallellt):

npx create-next-app@latest web --ts --eslint --tailwind
cd web
npm i @supabase/auth-helpers-nextjs @supabase/supabase-js @tanstack/react-query zod


Verifiera:

Vite: http://localhost:5173
 svarar.

Next.js: http://localhost:3000
 svarar.

Inloggning funkar server‑side (skyddade rutter återrenderar på servern).

17) Frontend – routes, state‑hooks, breakpoints, dark mode, i18n

Varför: Konsekvent UX.
Gör så här:

Routes‑lista (jobs, templates, runs, data, proxies, privacy, settings).

States via dev‑hooks (normal/loading/empty/error/forbidden) och storybook/preview.

Breakpoints Tailwind/TanStack layout, mobilt först.

Dark mode via Tailwind class + system‑pref.

i18n: lingui/next‑intl med locale‑filer sv-SE/en-US.

Kommandon:

# Generera “UI‑inventering” (DOM snapshot, statisk inventering, katalog)
npm run ui:inventory   # script som kör Playwright + DOM‑Exporter
# Lighthouse a11y
npm run audit:a11y


Verifiera:

Filer skapade i repo:

ui-inventory.dom.json + .csv

ui-inventory.static.json

ui-catalog.md

Lighthouse rapport visar ≥ 90 i Accessibility.

18) Syntetiska testsajter (E2E‑sandlåda)

Varför: Testa allt lokalt utan att slå externa sajter.
Gör så här:

Docker Compose som startar 3 sajter: statisk lista (pagination), infinite scroll, form‑flow.

E2E‑tester (Playwright) kör mot dessa.

Kommandon:

make docker-up-synthetic
# Kolla de tre sajterna
# http://localhost:8081, :8082, :8083 (exempel)
make docker-down-synthetic


Verifiera:

Alla tre svarar i webbläsaren.

npm run e2e (eller make e2e) passerar.

19) Tester – enhet, integration, E2E, property, mutation, fuzz

Varför: Kvalitet & regressionsskydd.
Gör så här:

Unit: selektorer, transformers, validators.

Integration: http scraper, browser scraper, scheduler, exports.

E2E: hela flöden mot syntetiska sajter.

Property‑based (Hypothesis) för selektorer/transformers.

Mutation‑testing (mutmut) på kritiska moduler.

Fuzz (AFL‑liknande) för HTML‑parser.

Performance (k6) & Chaos (döda worker, proxy‑degradering).

Kommandon:

make test       # allt
make test-unit
make test-integration
make test-e2e
make test-mutation
make test-fuzz
make perf-k6
make chaos


Verifiera:

Alla pipelines gröna, mutation score över tröskel (t.ex. ≥ 70%).

k6 visar P95 < definierad SLA.

20) Observability – loggar, metrics, tracing (Prometheus/Grafana/Otel)

Varför: Se vad som händer och reagera innan kunder märker.
Gör så här:

Strukturerade JSON‑loggar (correlation IDs).

Prometheus metrics från API, workers, proxy‑pool.

OpenTelemetry traces (OTLP till Tempo/Jaeger).

Grafana dashboards: scraping_overview, proxy_health, queues, db_dq, cost.

Kommandon:

docker compose -f monitoring/docker-compose.obsv.yml up -d
# API exponerar /metrics, Otel Collector tar emot traces


Verifiera:

Grafana uppe (t.ex. http://localhost:3001
).

Dashboards visar trafik, fel, latens, ban‑rate.

Larm (Alertmanager) triggar på trösklar (testa “smoke alert”).

21) Säkerhet – SAST, dep‑scan, container‑scan, SBOM, signing

Varför: Minska risk (sårbarheter, supply‑chain).
Gör så här:

SAST (Bandit, ruff‑rules), Dependabot/OSV‑scan, Trivy för images.

Skapa SBOM (Syft), signera images (Cosign), policy (Rekor/verify).

Secret‑scan (gitleaks/trufflehog) i pre‑commit och CI.

Kommandon:

make sast
make dep-scan
make image-scan
make sbom
make cosign-sign
make cosign-verify
``]
**Verifiera:**  
- CI artifacts innehåller rapporter; inga “High/Critical” kvar vid merge.  
- Cosign verify OK på publika images i registry.

---

# 22) CI/CD – GitHub Actions (build, test, sbom, release, deploy)

**Varför:** Automatisk kvalitet och snabb leverans.  
**Gör så här:**  
- Pipelines:  
  1) Lint/Type → 2) Unit → 3) Integration → 4) E2E → 5) Security → 6) SBOM/Sign → 7) Build & Push → 8) Deploy Staging → 9) Canary Prod → 10) Release notes.  
- Caching (pip/pnpm/Playwright), parallell matris (py 3.11/3.12, os).  
- Miljöhemligheter via GitHub Environments.

**Kommandon:**
```bash
# Lokalt “rökprov” innan push
make ci-local


Verifiera:

Alla workflows gröna.

Release skapad med changelog, image taggad app:vX.Y.Z.

23) API‑klienter & SDK (Python/TS), Postman/Insomnia

Varför: Snabb integration för konsumenter.
Gör så här:

Generera SDK från OpenAPI (/docs/openapi.yaml).

Publicera paket (privat registry eller GH Packages).

Postman/Insomnia export + exempel.

Kommandon:

make gen-openapi-clients
make sdk-publish


Verifiera:

pip install scraping-sdk==X.Y.Z fungerar; enkel kodsnutt hämtar data.

Postman‑samling kör tre scenarion utan fel.

24) Dokumentation komplett

Varför: Lätt att förstå, lätt att underhålla.
Gör så här:

Arkitektur, systemdesignbeslut (ADR), dev‑guide, usage‑guide, database schema, API‑docs, observability, security, runbooks (403 storm, 429 spike, proxy drought, restore drill), policies (robots/ToS toggle, GDPR/DPIA mallar).

UI‑katalog (ui-catalog.md), DSL‑manual med exempel.

Kommandon:

make docs-validate  # länk-kontroll, schema-koll, ADR-index


Verifiera:

Docs bygger (MkDocs/Docusaurus) och länkar fungerar.

Alla runbooks har “last reviewed” datum.

25) Produktion – Kubernetes/GCP (eller valfritt moln) + Supabase

Varför: Skalbar, robust drift.
Gör så här:

K8s manifester: namespace, configmaps, secrets (via External Secrets), deployments (api/workers/proxy‑pool), services, ingress, HPA, PDB, CronJobs (backup, retention, erasure, sbom, cost report).

Artifact registry (GCR/AR), Cloud Load Balancer/Ingress, Managed Prometheus/Grafana, GCS buckets (raw/html, exports, backups).

Supabase instans kopplad (eller egen Postgres på Cloud SQL med paritet).

Kommandon (exempel):

kubectl apply -k iac/k8s/
# eller Helm:
helm upgrade --install crawler ./docker/k8s/helm -f docker/k8s/helm/values.yaml


Verifiera:

kubectl get pods alla Running/Ready.

Ingress svarar 200, metrics skrapas, autoscaling triggar under last.

26) Kost & hushållning

Varför: Undvik överraskningar, rensa gammalt.
Gör så här:

Budget‑alerts, dashboards för kost (per komponent).

Lifecycle regler för buckets.

Städuppgifter (cron) för temp‑artefakter, gamla sessioner, misslyckade jobb.

Kommandon:

make cost-report
make gc


Verifiera:

Grafana “Cost Overview” uppdateras.

Buckets visar förväntat antal objekt efter lifecycle‑körning.

27) Backup, DR & övningar

Varför: När det brinner ska återställning sitta i ryggraden.
Gör så här:

Dagliga DB‑backuper (WAL‑G/pgBackRest) → GCS/S3 med retention.

Restore drill kvartalsvis (isolerad miljö), kontrollera checksums/integritet.

Export av kritiska configs (dashboards, alerts, policies).

Kommandon:

make backup-now
make restore-drill


Verifiera:

Återställningstid (RTO) & förlorad data (RPO) uppfyller mål.

Checklista signerad efter varje drill.

28) Efterlevnad & etiska kontroller (togglar + default‑safe)

Varför: Minimera juridisk risk och var “artigt” som standard.
Gör så här:

“Policy Toggle” i UI: robots/ToS‑respekt, rate‑limit‑nivåer, data‑minimering.

DPIA‑mall ifylld för typiska datakällor; privacy center dokumenterat.

Audit log av policy‑ändringar.

Kommandon:

make policy-check


Verifiera:

Policy‑ändringar loggas, export av audit log körbar.

29) Release‑process & semver

Varför: Förutsägbar leverans.
Gör så här:

Conventional commits → auto‑changelog.

Semver taggning, release‑notes pipeline, canary → prod promotion.

Feature flags för riskabla delar.

Kommandon:

make release TYPE=minor


Verifiera:

Ny tag och GitHub Release med länkat changelog.

Canary‑trafik visar noll/acceptabel felgrad före full rollout.

30) Operativ drift – daglig checklista

Varför: Mindre brandkårsutryckningar.
Gör så här:

Daglig hälsorapport (graf, felkvot, proxyhälsa, ködjup, kost).

Pager‑regler vid larm med tydliga “first actions”.

Veckovis städning och “selector regression suite” nattlig.

Kommandon:

make daily-report
make nightly-selector-regression


Verifiera:

Rapport skickas till Slack/email; regression‑suite rapporterar “0 drift”.

Extra: detaljerade “klar‑kriterier” per modul (kortfattat)

Crawler: inga duplicat, inga loopar, rätt djup, sitemap densitet över tröskel, policy per domän aktiv.

Scraper: auto‑diagnose väljer HTTP→browser korrekt, P95 render‑tid < SLA, resursblockering sparar ≥30% bandbredd.

Templates/DSL: validering sträng, fallback‑selektorer funkar, transformationsbibliotek täcker 95% fält.

Proxy‑pool: hälsoscore uppdateras; ban‑rate < definierad mål (t.ex. <2%).

Scheduler: jobb kan pausas/återupptas; poison queue isolerar “värstingar”.

DB/RLS: alla SELECT/INSERT respekterar roll; erasure/retention loggade.

Exports: stora dataset fungerar (chunking, idempotens).

Frontend: alla rutter listade; alla UI‑states demonstrerade; mobil/tablet/desktop pixel‑perf; dark mode class‑toggle OK; i18n 100% täckning.

Observability: dashboards färdiga; alert‑regler med runbooks; spårbarhet med correlation‑IDs.

Security: SAST/deps/container scan gröna; SBOM skapad & signerad; secrets aldrig i Git.

CI/CD: alla jobb gröna; artifacts bevarade; rollback via Helm/Argo kubectl fungerar.

Prod/K8s: HPA skalar upp/ner på last; PDB hindrar total nertid; CronJobs körs och loggas.

Docs: ADRs för större beslut; API‑docs uppdaterade; “first hour” guide för nya devs.

DR: bevisad restore‑drill inom mål‑RTO/RPO.

Operations: daily/weekly körs; månadens rapport signeras.

Snabb körordning (om du vill “bocka av” från noll)

Miljö & verktyg (pkt 2–3) → pre-commit, .env, config/*.

DB lokalt (pkt 4 & 13) → docker up db, make db-migrate, db-seed.

Backend (pkt 5–6) → make run-api, OpenAPI/GraphQL, auth‑checks.

Syntetiska sajter (pkt 18) → make docker-up-synthetic.

Crawler/Scraper (pkt 7–12) → första end‑to‑end‑körning, templates.

Observability (pkt 20) → Prometheus/Grafana/Otel upp; dashboards.

Tester (pkt 19) → allt grönt inkl. E2E.

Frontend (pkt 16–17) → kör Vite nu; kör Next.js POC parallellt.

Exports/Privacy (pkt 14–15) → retention/erasure & exporters.

Security & CI/CD (pkt 21–22) → pipelines, sbom/sign.

Docs & SDK (pkt 23–24).

Prod/K8s/GCP (pkt 25–27) → staging → canary → prod.

Operations (pkt 28–30).